{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "ts0QzDvtKBcM",
        "outputId": "d435449e-5db1-4f72-b9c2-424c9c076faa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b481bdc6-51de-4f03-88fa-8c9ee51e4ede\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b481bdc6-51de-4f03-88fa-8c9ee51e4ede')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b481bdc6-51de-4f03-88fa-8c9ee51e4ede button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b481bdc6-51de-4f03-88fa-8c9ee51e4ede');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd \n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dla-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app_counts=application_df['APPLICATION_TYPE'].value_counts()\n",
        "\n",
        "# uses the variable name `application_types_to_replace`\n",
        "max_app_counts = 15\n",
        "\n",
        "application_types_to_replace = app_counts[app_counts<max_app_counts].index.tolist()\n",
        "# Replaces in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsPycZsSSAVc",
        "outputId": "f4f189be-6e82-403c-e633-5742745ef31f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "T9         156\n",
              "T13         66\n",
              "T12         27\n",
              "T2          16\n",
              "Other       11\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "# uses the variable name `classifications_to_replace`\n",
        "max_classcount = 25\n",
        "classifications_to_replace = class_counts[class_counts<max_classcount].index.tolist()\n",
        "# Replaces in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy4N6UybT_fr",
        "outputId": "8551108f-c1ba-4a78-a8ef-1d49951011b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "Other      227\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "application_df['NAME'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02dljVHHp2x7",
        "outputId": "d184f412-de55-4a6b-9909-dd5437598291"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PARENT BOOSTER USA INC                                                  1260\n",
              "TOPS CLUB INC                                                            765\n",
              "UNITED STATES BOWLING CONGRESS INC                                       700\n",
              "WASHINGTON STATE UNIVERSITY                                              492\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                          408\n",
              "                                                                        ... \n",
              "ST LOUIS SLAM WOMENS FOOTBALL                                              1\n",
              "AIESEC ALUMNI IBEROAMERICA CORP                                            1\n",
              "WEALLBLEEDRED ORG INC                                                      1\n",
              "AMERICAN SOCIETY FOR STANDARDS IN MEDIUMSHIP & PSYCHICAL INVESTIGATI       1\n",
              "WATERHOUSE CHARITABLE TR                                                   1\n",
              "Name: NAME, Length: 19568, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_counts = application_df['NAME'].value_counts()\n",
        "max_namecount = 100\n",
        "names_to_replace = name_counts[name_counts<max_namecount].index.tolist()\n",
        "# Replaces in dataframe\n",
        "for nme in names_to_replace:\n",
        "    application_df['NAME'] = application_df['NAME'].replace(nme,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['NAME'].value_counts()"
      ],
      "metadata": {
        "id": "NXpZWZ_MqNz3",
        "outputId": "2684f501-82ea-4bfc-bd20-c6c3f47ae5aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other                                                                 25987\n",
              "PARENT BOOSTER USA INC                                                 1260\n",
              "TOPS CLUB INC                                                           765\n",
              "UNITED STATES BOWLING CONGRESS INC                                      700\n",
              "WASHINGTON STATE UNIVERSITY                                             492\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                         408\n",
              "PTA TEXAS CONGRESS                                                      368\n",
              "SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC                           331\n",
              "ALPHA PHI SIGMA                                                         313\n",
              "TOASTMASTERS INTERNATIONAL                                              293\n",
              "MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS                       287\n",
              "LITTLE LEAGUE BASEBALL INC                                              277\n",
              "INTERNATIONAL ASSOCIATION OF LIONS CLUBS                                266\n",
              "MOMS CLUB                                                               210\n",
              "INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL & TRANSPORTATION      206\n",
              "AMERICAN ASSOCIATION OF UNIVERSITY WOMEN                                197\n",
              "FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA                    166\n",
              "KNIGHTS OF COLUMBUS                                                     158\n",
              "HABITAT FOR HUMANITY INTERNATIONAL INC                                  154\n",
              "TENNESSEE ORDER OF THE EASTERN STAR                                     151\n",
              "VETERANS OF FOREIGN WARS OF THE UNITED STATES AUXILIARY                 144\n",
              "PTA UTAH CONGRESS                                                       140\n",
              "THE UNITED STATES PONY CLUBS INC                                        136\n",
              "CIVITAN INTERNATIONAL                                                   131\n",
              "SIGMA BETA DELTA INC                                                    127\n",
              "HONOR SOCIETY OF PHI KAPPA PHI                                          107\n",
              "MONTANA 4-H FOUNDATION INC                                              107\n",
              "WASHINGTON STATE GRANGE                                                 106\n",
              "UNIVERSITY OF WYOMING                                                   105\n",
              "DEMOLAY INTERNATIONAL                                                   104\n",
              "SERTOMA INC                                                             103\n",
              "Name: NAME, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts categorical data to numeric with `pd.get_dummies`\n",
        "dummy_cats = ['NAME','APPLICATION_TYPE','AFFILIATION','CLASSIFICATION','USE_CASE','ORGANIZATION','STATUS','INCOME_AMT','SPECIAL_CONSIDERATIONS']\n",
        "dummies_df=pd.get_dummies(application_df, columns=dummy_cats)\n",
        "\n",
        "dummies_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "I0GTNeS2URQA",
        "outputId": "3a0b0aed-7c97-43d2-fae7-0ad4db949daf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             EIN   ASK_AMT  IS_SUCCESSFUL  NAME_ALPHA PHI SIGMA  \\\n",
              "0       10520599      5000              1                     0   \n",
              "1       10531628    108590              1                     0   \n",
              "2       10547893      5000              0                     0   \n",
              "3       10553066      6692              1                     0   \n",
              "4       10556103    142590              1                     0   \n",
              "...          ...       ...            ...                   ...   \n",
              "34294  996009318      5000              0                     0   \n",
              "34295  996010315      5000              0                     0   \n",
              "34296  996012607      5000              0                     0   \n",
              "34297  996015768      5000              1                     0   \n",
              "34298  996086871  36500179              0                     0   \n",
              "\n",
              "       NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC  \\\n",
              "0                                                      0      \n",
              "1                                                      0      \n",
              "2                                                      0      \n",
              "3                                                      0      \n",
              "4                                                      0      \n",
              "...                                                  ...      \n",
              "34294                                                  0      \n",
              "34295                                                  0      \n",
              "34296                                                  0      \n",
              "34297                                                  0      \n",
              "34298                                                  0      \n",
              "\n",
              "       NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN  \\\n",
              "0                                                  0   \n",
              "1                                                  0   \n",
              "2                                                  0   \n",
              "3                                                  0   \n",
              "4                                                  0   \n",
              "...                                              ...   \n",
              "34294                                              0   \n",
              "34295                                              0   \n",
              "34296                                              0   \n",
              "34297                                              0   \n",
              "34298                                              0   \n",
              "\n",
              "       NAME_CIVITAN INTERNATIONAL  NAME_DEMOLAY INTERNATIONAL  \\\n",
              "0                               0                           0   \n",
              "1                               0                           0   \n",
              "2                               0                           0   \n",
              "3                               0                           0   \n",
              "4                               0                           0   \n",
              "...                           ...                         ...   \n",
              "34294                           0                           0   \n",
              "34295                           0                           0   \n",
              "34296                           0                           0   \n",
              "34297                           0                           0   \n",
              "34298                           0                           0   \n",
              "\n",
              "       NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA  \\\n",
              "0                                                      0           \n",
              "1                                                      0           \n",
              "2                                                      0           \n",
              "3                                                      0           \n",
              "4                                                      0           \n",
              "...                                                  ...           \n",
              "34294                                                  0           \n",
              "34295                                                  0           \n",
              "34296                                                  0           \n",
              "34297                                                  0           \n",
              "34298                                                  0           \n",
              "\n",
              "       NAME_HABITAT FOR HUMANITY INTERNATIONAL INC  ...  INCOME_AMT_1-9999  \\\n",
              "0                                                0  ...                  0   \n",
              "1                                                0  ...                  1   \n",
              "2                                                0  ...                  0   \n",
              "3                                                0  ...                  0   \n",
              "4                                                0  ...                  0   \n",
              "...                                            ...  ...                ...   \n",
              "34294                                            0  ...                  0   \n",
              "34295                                            0  ...                  0   \n",
              "34296                                            0  ...                  0   \n",
              "34297                                            0  ...                  0   \n",
              "34298                                            0  ...                  0   \n",
              "\n",
              "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                           0                         0                   0   \n",
              "1                           0                         0                   0   \n",
              "2                           0                         0                   0   \n",
              "3                           1                         0                   0   \n",
              "4                           0                         1                   0   \n",
              "...                       ...                       ...                 ...   \n",
              "34294                       0                         0                   0   \n",
              "34295                       0                         0                   0   \n",
              "34296                       0                         0                   0   \n",
              "34297                       0                         0                   0   \n",
              "34298                       0                         0                   0   \n",
              "\n",
              "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0                     0                       0                0   \n",
              "1                     0                       0                0   \n",
              "2                     0                       0                0   \n",
              "3                     0                       0                0   \n",
              "4                     0                       0                0   \n",
              "...                 ...                     ...              ...   \n",
              "34294                 0                       0                0   \n",
              "34295                 0                       0                0   \n",
              "34296                 0                       0                0   \n",
              "34297                 0                       0                0   \n",
              "34298                 1                       0                0   \n",
              "\n",
              "       INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
              "0                      0                         1                         0  \n",
              "1                      0                         1                         0  \n",
              "2                      0                         1                         0  \n",
              "3                      0                         1                         0  \n",
              "4                      0                         1                         0  \n",
              "...                  ...                       ...                       ...  \n",
              "34294                  0                         1                         0  \n",
              "34295                  0                         1                         0  \n",
              "34296                  0                         1                         0  \n",
              "34297                  0                         1                         0  \n",
              "34298                  0                         1                         0  \n",
              "\n",
              "[34299 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5a2148d-115b-4aff-a267-ab1561cb6e1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>NAME_ALPHA PHI SIGMA</th>\n",
              "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
              "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
              "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
              "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
              "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
              "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>996009318</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>996010315</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>996012607</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>996015768</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>996086871</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows Ã— 96 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5a2148d-115b-4aff-a267-ab1561cb6e1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e5a2148d-115b-4aff-a267-ab1561cb6e1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e5a2148d-115b-4aff-a267-ab1561cb6e1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splits  preprocessed data into our features and target arrays\n",
        "y = dummies_df['IS_SUCCESSFUL'].values\n",
        "X = dummies_df.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n"
      ],
      "metadata": {
        "id": "un3HhB6qVpvz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "6F0MkbJQxlbF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test_scaled[0])"
      ],
      "metadata": {
        "id": "SE4B3Ac2tWwS",
        "outputId": "0482538f-bbcc-4037-b033-4550f25fed51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIMIZATION ATTEMPT 1: 'ALTERED BINS, ADDED NEURONS, ADDED EPOCHS'\n",
        "# using the neuron rule of thumb, but making it two times the amount of features after numericizing the categorical data (190 neurons).\n",
        "\n",
        "# Defines the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer_1= 2*number_input_features\n",
        "hidden_nodes_layer_2 = 2*number_input_features\n",
        "hidden_nodes_layer_3 = 2*number_input_features\n",
        "\n",
        "nn1 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn1.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer_1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer_2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "nn1.summary()"
      ],
      "metadata": {
        "id": "M7MaAFe9zcMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3882b3d8-b735-4d72-ff1b-f21aa9eab7e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 190)               18240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 190)               36290     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 191       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,721\n",
            "Trainable params: 54,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "GXtZHFivdGMD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = nn1.fit(X_train_scaled,y_train,epochs=150, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESmibfmAdLTj",
        "outputId": "c4739f9a-6477-4d79-b76d-171130c1ca59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "804/804 [==============================] - 7s 6ms/step - loss: 0.5116 - accuracy: 0.7444 - val_loss: 0.5091 - val_accuracy: 0.7473\n",
            "Epoch 2/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4916 - accuracy: 0.7587 - val_loss: 0.4995 - val_accuracy: 0.7516\n",
            "Epoch 3/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4868 - accuracy: 0.7608 - val_loss: 0.4952 - val_accuracy: 0.7502\n",
            "Epoch 4/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4851 - accuracy: 0.7610 - val_loss: 0.4945 - val_accuracy: 0.7515\n",
            "Epoch 5/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4830 - accuracy: 0.7633 - val_loss: 0.4944 - val_accuracy: 0.7507\n",
            "Epoch 6/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4815 - accuracy: 0.7645 - val_loss: 0.5015 - val_accuracy: 0.7522\n",
            "Epoch 7/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4807 - accuracy: 0.7653 - val_loss: 0.4945 - val_accuracy: 0.7536\n",
            "Epoch 8/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4795 - accuracy: 0.7662 - val_loss: 0.4931 - val_accuracy: 0.7548\n",
            "Epoch 9/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4790 - accuracy: 0.7655 - val_loss: 0.4950 - val_accuracy: 0.7523\n",
            "Epoch 10/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4771 - accuracy: 0.7666 - val_loss: 0.4935 - val_accuracy: 0.7521\n",
            "Epoch 11/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4770 - accuracy: 0.7681 - val_loss: 0.4959 - val_accuracy: 0.7511\n",
            "Epoch 12/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4754 - accuracy: 0.7679 - val_loss: 0.4944 - val_accuracy: 0.7499\n",
            "Epoch 13/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4744 - accuracy: 0.7700 - val_loss: 0.4937 - val_accuracy: 0.7535\n",
            "Epoch 14/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4736 - accuracy: 0.7687 - val_loss: 0.4919 - val_accuracy: 0.7536\n",
            "Epoch 15/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4727 - accuracy: 0.7697 - val_loss: 0.4950 - val_accuracy: 0.7536\n",
            "Epoch 16/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4715 - accuracy: 0.7699 - val_loss: 0.4937 - val_accuracy: 0.7521\n",
            "Epoch 17/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4705 - accuracy: 0.7701 - val_loss: 0.4948 - val_accuracy: 0.7538\n",
            "Epoch 18/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4704 - accuracy: 0.7708 - val_loss: 0.4985 - val_accuracy: 0.7509\n",
            "Epoch 19/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4699 - accuracy: 0.7706 - val_loss: 0.4938 - val_accuracy: 0.7536\n",
            "Epoch 20/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4690 - accuracy: 0.7723 - val_loss: 0.4936 - val_accuracy: 0.7528\n",
            "Epoch 21/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4678 - accuracy: 0.7737 - val_loss: 0.4966 - val_accuracy: 0.7513\n",
            "Epoch 22/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4674 - accuracy: 0.7735 - val_loss: 0.4938 - val_accuracy: 0.7544\n",
            "Epoch 23/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4661 - accuracy: 0.7738 - val_loss: 0.4962 - val_accuracy: 0.7537\n",
            "Epoch 24/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4655 - accuracy: 0.7736 - val_loss: 0.5001 - val_accuracy: 0.7517\n",
            "Epoch 25/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4651 - accuracy: 0.7738 - val_loss: 0.4978 - val_accuracy: 0.7551\n",
            "Epoch 26/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4639 - accuracy: 0.7745 - val_loss: 0.4989 - val_accuracy: 0.7535\n",
            "Epoch 27/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4637 - accuracy: 0.7742 - val_loss: 0.5002 - val_accuracy: 0.7534\n",
            "Epoch 28/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4629 - accuracy: 0.7754 - val_loss: 0.4994 - val_accuracy: 0.7550\n",
            "Epoch 29/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4627 - accuracy: 0.7759 - val_loss: 0.4951 - val_accuracy: 0.7536\n",
            "Epoch 30/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4615 - accuracy: 0.7760 - val_loss: 0.5032 - val_accuracy: 0.7541\n",
            "Epoch 31/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4610 - accuracy: 0.7761 - val_loss: 0.4984 - val_accuracy: 0.7522\n",
            "Epoch 32/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4608 - accuracy: 0.7769 - val_loss: 0.5013 - val_accuracy: 0.7559\n",
            "Epoch 33/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.5024 - val_accuracy: 0.7558\n",
            "Epoch 34/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.5018 - val_accuracy: 0.7545\n",
            "Epoch 35/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4589 - accuracy: 0.7773 - val_loss: 0.5048 - val_accuracy: 0.7525\n",
            "Epoch 36/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4587 - accuracy: 0.7773 - val_loss: 0.5007 - val_accuracy: 0.7546\n",
            "Epoch 37/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4575 - accuracy: 0.7776 - val_loss: 0.5093 - val_accuracy: 0.7495\n",
            "Epoch 38/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4571 - accuracy: 0.7773 - val_loss: 0.5043 - val_accuracy: 0.7563\n",
            "Epoch 39/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.5048 - val_accuracy: 0.7555\n",
            "Epoch 40/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7573\n",
            "Epoch 41/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4561 - accuracy: 0.7786 - val_loss: 0.5030 - val_accuracy: 0.7548\n",
            "Epoch 42/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4553 - accuracy: 0.7794 - val_loss: 0.5078 - val_accuracy: 0.7549\n",
            "Epoch 43/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4548 - accuracy: 0.7793 - val_loss: 0.5088 - val_accuracy: 0.7551\n",
            "Epoch 44/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4553 - accuracy: 0.7792 - val_loss: 0.5089 - val_accuracy: 0.7529\n",
            "Epoch 45/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4542 - accuracy: 0.7794 - val_loss: 0.5076 - val_accuracy: 0.7549\n",
            "Epoch 46/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4540 - accuracy: 0.7803 - val_loss: 0.5077 - val_accuracy: 0.7549\n",
            "Epoch 47/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4534 - accuracy: 0.7795 - val_loss: 0.5130 - val_accuracy: 0.7546\n",
            "Epoch 48/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4526 - accuracy: 0.7811 - val_loss: 0.5134 - val_accuracy: 0.7535\n",
            "Epoch 49/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4535 - accuracy: 0.7802 - val_loss: 0.5112 - val_accuracy: 0.7578\n",
            "Epoch 50/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4527 - accuracy: 0.7813 - val_loss: 0.5058 - val_accuracy: 0.7555\n",
            "Epoch 51/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4519 - accuracy: 0.7811 - val_loss: 0.5138 - val_accuracy: 0.7569\n",
            "Epoch 52/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4516 - accuracy: 0.7819 - val_loss: 0.5154 - val_accuracy: 0.7553\n",
            "Epoch 53/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4505 - accuracy: 0.7822 - val_loss: 0.5138 - val_accuracy: 0.7531\n",
            "Epoch 54/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4512 - accuracy: 0.7808 - val_loss: 0.5152 - val_accuracy: 0.7583\n",
            "Epoch 55/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4502 - accuracy: 0.7817 - val_loss: 0.5120 - val_accuracy: 0.7585\n",
            "Epoch 56/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4506 - accuracy: 0.7814 - val_loss: 0.5184 - val_accuracy: 0.7559\n",
            "Epoch 57/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4496 - accuracy: 0.7818 - val_loss: 0.5234 - val_accuracy: 0.7553\n",
            "Epoch 58/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4500 - accuracy: 0.7813 - val_loss: 0.5213 - val_accuracy: 0.7551\n",
            "Epoch 59/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4493 - accuracy: 0.7813 - val_loss: 0.5193 - val_accuracy: 0.7560\n",
            "Epoch 60/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4491 - accuracy: 0.7832 - val_loss: 0.5272 - val_accuracy: 0.7543\n",
            "Epoch 61/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4486 - accuracy: 0.7834 - val_loss: 0.5208 - val_accuracy: 0.7584\n",
            "Epoch 62/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4475 - accuracy: 0.7827 - val_loss: 0.5270 - val_accuracy: 0.7546\n",
            "Epoch 63/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4479 - accuracy: 0.7830 - val_loss: 0.5227 - val_accuracy: 0.7559\n",
            "Epoch 64/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4473 - accuracy: 0.7816 - val_loss: 0.5197 - val_accuracy: 0.7562\n",
            "Epoch 65/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4467 - accuracy: 0.7832 - val_loss: 0.5238 - val_accuracy: 0.7585\n",
            "Epoch 66/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4462 - accuracy: 0.7842 - val_loss: 0.5217 - val_accuracy: 0.7570\n",
            "Epoch 67/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4467 - accuracy: 0.7844 - val_loss: 0.5250 - val_accuracy: 0.7538\n",
            "Epoch 68/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4459 - accuracy: 0.7835 - val_loss: 0.5299 - val_accuracy: 0.7555\n",
            "Epoch 69/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4466 - accuracy: 0.7839 - val_loss: 0.5254 - val_accuracy: 0.7565\n",
            "Epoch 70/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4464 - accuracy: 0.7849 - val_loss: 0.5296 - val_accuracy: 0.7562\n",
            "Epoch 71/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4452 - accuracy: 0.7851 - val_loss: 0.5259 - val_accuracy: 0.7546\n",
            "Epoch 72/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4449 - accuracy: 0.7838 - val_loss: 0.5262 - val_accuracy: 0.7558\n",
            "Epoch 73/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4445 - accuracy: 0.7837 - val_loss: 0.5294 - val_accuracy: 0.7584\n",
            "Epoch 74/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4444 - accuracy: 0.7844 - val_loss: 0.5284 - val_accuracy: 0.7586\n",
            "Epoch 75/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4444 - accuracy: 0.7837 - val_loss: 0.5269 - val_accuracy: 0.7570\n",
            "Epoch 76/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4434 - accuracy: 0.7842 - val_loss: 0.5377 - val_accuracy: 0.7571\n",
            "Epoch 77/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4469 - accuracy: 0.7843 - val_loss: 0.5340 - val_accuracy: 0.7556\n",
            "Epoch 78/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4433 - accuracy: 0.7841 - val_loss: 0.5383 - val_accuracy: 0.7544\n",
            "Epoch 79/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4422 - accuracy: 0.7857 - val_loss: 0.5493 - val_accuracy: 0.7521\n",
            "Epoch 80/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4434 - accuracy: 0.7848 - val_loss: 0.5397 - val_accuracy: 0.7557\n",
            "Epoch 81/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4426 - accuracy: 0.7859 - val_loss: 0.5420 - val_accuracy: 0.7558\n",
            "Epoch 82/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4427 - accuracy: 0.7859 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
            "Epoch 83/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4424 - accuracy: 0.7854 - val_loss: 0.5379 - val_accuracy: 0.7524\n",
            "Epoch 84/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4427 - accuracy: 0.7855 - val_loss: 0.5421 - val_accuracy: 0.7566\n",
            "Epoch 85/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4415 - accuracy: 0.7860 - val_loss: 0.5357 - val_accuracy: 0.7565\n",
            "Epoch 86/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4417 - accuracy: 0.7852 - val_loss: 0.5404 - val_accuracy: 0.7548\n",
            "Epoch 87/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4418 - accuracy: 0.7849 - val_loss: 0.5374 - val_accuracy: 0.7545\n",
            "Epoch 88/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4414 - accuracy: 0.7860 - val_loss: 0.5379 - val_accuracy: 0.7562\n",
            "Epoch 89/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4413 - accuracy: 0.7851 - val_loss: 0.5419 - val_accuracy: 0.7545\n",
            "Epoch 90/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4433 - accuracy: 0.7857 - val_loss: 0.5377 - val_accuracy: 0.7573\n",
            "Epoch 91/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4413 - accuracy: 0.7853 - val_loss: 0.5382 - val_accuracy: 0.7544\n",
            "Epoch 92/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4404 - accuracy: 0.7858 - val_loss: 0.5409 - val_accuracy: 0.7535\n",
            "Epoch 93/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4398 - accuracy: 0.7855 - val_loss: 0.5457 - val_accuracy: 0.7567\n",
            "Epoch 94/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4398 - accuracy: 0.7877 - val_loss: 0.5477 - val_accuracy: 0.7541\n",
            "Epoch 95/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4404 - accuracy: 0.7858 - val_loss: 0.5466 - val_accuracy: 0.7534\n",
            "Epoch 96/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4403 - accuracy: 0.7867 - val_loss: 0.5383 - val_accuracy: 0.7566\n",
            "Epoch 97/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4399 - accuracy: 0.7861 - val_loss: 0.5484 - val_accuracy: 0.7577\n",
            "Epoch 98/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4393 - accuracy: 0.7861 - val_loss: 0.5536 - val_accuracy: 0.7567\n",
            "Epoch 99/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4393 - accuracy: 0.7856 - val_loss: 0.5471 - val_accuracy: 0.7567\n",
            "Epoch 100/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4389 - accuracy: 0.7860 - val_loss: 0.5601 - val_accuracy: 0.7542\n",
            "Epoch 101/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4392 - accuracy: 0.7849 - val_loss: 0.5534 - val_accuracy: 0.7539\n",
            "Epoch 102/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4391 - accuracy: 0.7868 - val_loss: 0.5460 - val_accuracy: 0.7570\n",
            "Epoch 103/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4377 - accuracy: 0.7864 - val_loss: 0.5479 - val_accuracy: 0.7544\n",
            "Epoch 104/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4383 - accuracy: 0.7874 - val_loss: 0.5454 - val_accuracy: 0.7542\n",
            "Epoch 105/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4397 - accuracy: 0.7856 - val_loss: 0.5495 - val_accuracy: 0.7564\n",
            "Epoch 106/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4385 - accuracy: 0.7856 - val_loss: 0.5663 - val_accuracy: 0.7535\n",
            "Epoch 107/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4374 - accuracy: 0.7867 - val_loss: 0.5627 - val_accuracy: 0.7565\n",
            "Epoch 108/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4381 - accuracy: 0.7857 - val_loss: 0.5547 - val_accuracy: 0.7563\n",
            "Epoch 109/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4370 - accuracy: 0.7862 - val_loss: 0.5548 - val_accuracy: 0.7559\n",
            "Epoch 110/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4522 - accuracy: 0.7861 - val_loss: 0.5739 - val_accuracy: 0.7567\n",
            "Epoch 111/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4361 - accuracy: 0.7869 - val_loss: 0.5707 - val_accuracy: 0.7569\n",
            "Epoch 112/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4356 - accuracy: 0.7878 - val_loss: 0.5800 - val_accuracy: 0.7550\n",
            "Epoch 113/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4352 - accuracy: 0.7877 - val_loss: 0.5741 - val_accuracy: 0.7562\n",
            "Epoch 114/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4350 - accuracy: 0.7879 - val_loss: 0.5774 - val_accuracy: 0.7527\n",
            "Epoch 115/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4371 - accuracy: 0.7873 - val_loss: 0.5788 - val_accuracy: 0.7576\n",
            "Epoch 116/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4355 - accuracy: 0.7881 - val_loss: 0.5736 - val_accuracy: 0.7563\n",
            "Epoch 117/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4354 - accuracy: 0.7874 - val_loss: 0.5761 - val_accuracy: 0.7544\n",
            "Epoch 118/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4376 - accuracy: 0.7877 - val_loss: 0.5830 - val_accuracy: 0.7534\n",
            "Epoch 119/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4365 - accuracy: 0.7879 - val_loss: 0.5736 - val_accuracy: 0.7541\n",
            "Epoch 120/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4352 - accuracy: 0.7880 - val_loss: 0.5733 - val_accuracy: 0.7555\n",
            "Epoch 121/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4353 - accuracy: 0.7881 - val_loss: 0.5694 - val_accuracy: 0.7543\n",
            "Epoch 122/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4349 - accuracy: 0.7878 - val_loss: 0.5808 - val_accuracy: 0.7542\n",
            "Epoch 123/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4360 - accuracy: 0.7887 - val_loss: 0.5737 - val_accuracy: 0.7545\n",
            "Epoch 124/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4418 - accuracy: 0.7881 - val_loss: 0.5773 - val_accuracy: 0.7520\n",
            "Epoch 125/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4351 - accuracy: 0.7898 - val_loss: 0.5858 - val_accuracy: 0.7520\n",
            "Epoch 126/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4369 - accuracy: 0.7886 - val_loss: 0.5819 - val_accuracy: 0.7539\n",
            "Epoch 127/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4342 - accuracy: 0.7879 - val_loss: 0.5844 - val_accuracy: 0.7530\n",
            "Epoch 128/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4345 - accuracy: 0.7870 - val_loss: 0.5775 - val_accuracy: 0.7555\n",
            "Epoch 129/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4341 - accuracy: 0.7877 - val_loss: 0.5760 - val_accuracy: 0.7560\n",
            "Epoch 130/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4342 - accuracy: 0.7883 - val_loss: 0.5759 - val_accuracy: 0.7586\n",
            "Epoch 131/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4352 - accuracy: 0.7887 - val_loss: 0.5762 - val_accuracy: 0.7536\n",
            "Epoch 132/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4340 - accuracy: 0.7893 - val_loss: 0.5872 - val_accuracy: 0.7552\n",
            "Epoch 133/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4344 - accuracy: 0.7898 - val_loss: 0.5857 - val_accuracy: 0.7548\n",
            "Epoch 134/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4340 - accuracy: 0.7888 - val_loss: 0.5877 - val_accuracy: 0.7541\n",
            "Epoch 135/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4345 - accuracy: 0.7885 - val_loss: 0.5791 - val_accuracy: 0.7555\n",
            "Epoch 136/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4329 - accuracy: 0.7897 - val_loss: 0.5883 - val_accuracy: 0.7557\n",
            "Epoch 137/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4387 - accuracy: 0.7885 - val_loss: 0.5821 - val_accuracy: 0.7509\n",
            "Epoch 138/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4338 - accuracy: 0.7885 - val_loss: 0.5930 - val_accuracy: 0.7552\n",
            "Epoch 139/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4337 - accuracy: 0.7887 - val_loss: 0.5860 - val_accuracy: 0.7559\n",
            "Epoch 140/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4327 - accuracy: 0.7904 - val_loss: 0.5940 - val_accuracy: 0.7571\n",
            "Epoch 141/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4316 - accuracy: 0.7892 - val_loss: 0.5890 - val_accuracy: 0.7536\n",
            "Epoch 142/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4327 - accuracy: 0.7889 - val_loss: 0.5951 - val_accuracy: 0.7527\n",
            "Epoch 143/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4334 - accuracy: 0.7886 - val_loss: 0.5892 - val_accuracy: 0.7551\n",
            "Epoch 144/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4332 - accuracy: 0.7891 - val_loss: 0.6039 - val_accuracy: 0.7550\n",
            "Epoch 145/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4323 - accuracy: 0.7895 - val_loss: 0.5986 - val_accuracy: 0.7517\n",
            "Epoch 146/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4317 - accuracy: 0.7901 - val_loss: 0.6057 - val_accuracy: 0.7551\n",
            "Epoch 147/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4326 - accuracy: 0.7889 - val_loss: 0.6010 - val_accuracy: 0.7521\n",
            "Epoch 148/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4335 - accuracy: 0.7896 - val_loss: 0.5998 - val_accuracy: 0.7542\n",
            "Epoch 149/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4331 - accuracy: 0.7892 - val_loss: 0.6066 - val_accuracy: 0.7530\n",
            "Epoch 150/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4314 - accuracy: 0.7889 - val_loss: 0.6053 - val_accuracy: 0.7513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluates Optimization model 1 using the test data\n",
        "#Optimization model meets the >75% threshold.\n",
        "model_loss, model_accuracy = nn1.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcmBS0oUjFhi",
        "outputId": "8f66e53e-f964-4998-f207-6e5654e72acf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.6053 - accuracy: 0.7513 - 355ms/epoch - 1ms/step\n",
            "Loss: 0.6052975058555603, Accuracy: 0.7512536644935608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_df = pd.DataFrame(fit_model.history)\n",
        "history_df.index += 1\n",
        "history_df.plot(y=\"accuracy\",title=\"Optimization Attempt 1\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "gNKGOnHUxY0W",
        "outputId": "e8653028-0f9c-4829-f806-a5539ab1c384"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves Optimization model 1 to HDF5\n",
        "nn1.save('AlphabetSoupCharity_Optimisation1.h5')"
      ],
      "metadata": {
        "id": "qW-t_ll-joD-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIMIZATION ATTEMPT #2 REVISED BINS, ADDED LAYER, STEPPED NEURONS, ADDED EPOCHS\n",
        "## Adding fourth layer (1 input, 2 hidden, 1 output) consisting of the same amount of neurons.\n",
        "##Neurons are stepped up in size.\n",
        "\n",
        "\n",
        "hidden_nodes_layer_1= number_input_features\n",
        "hidden_nodes_layer_2 = 2*number_input_features\n",
        "hidden_nodes_layer_3 = 3*number_input_features\n",
        "nn2 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn2.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer_1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer_2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Third hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer_3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "nn2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tffnrcfjKMp",
        "outputId": "d6e75d1b-d290-4f51-8a0c-3d1f07196ef6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 95)                9120      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 190)               18240     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 285)               54435     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 286       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,081\n",
            "Trainable params: 82,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiles the model\n",
        "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yluj6Hk6l0Dv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = nn2.fit(X_train_scaled,y_train,epochs=150, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN4xbeXal99b",
        "outputId": "bc4af705-a7dd-422c-e49c-5b07d049f371"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.5115 - accuracy: 0.7476 - val_loss: 0.4979 - val_accuracy: 0.7486\n",
            "Epoch 2/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4904 - accuracy: 0.7595 - val_loss: 0.4987 - val_accuracy: 0.7513\n",
            "Epoch 3/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4858 - accuracy: 0.7604 - val_loss: 0.4971 - val_accuracy: 0.7522\n",
            "Epoch 4/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4846 - accuracy: 0.7627 - val_loss: 0.4965 - val_accuracy: 0.7532\n",
            "Epoch 5/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4821 - accuracy: 0.7642 - val_loss: 0.4922 - val_accuracy: 0.7515\n",
            "Epoch 6/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4813 - accuracy: 0.7650 - val_loss: 0.4931 - val_accuracy: 0.7522\n",
            "Epoch 7/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4797 - accuracy: 0.7642 - val_loss: 0.4954 - val_accuracy: 0.7513\n",
            "Epoch 8/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4785 - accuracy: 0.7661 - val_loss: 0.4968 - val_accuracy: 0.7565\n",
            "Epoch 9/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4783 - accuracy: 0.7671 - val_loss: 0.4923 - val_accuracy: 0.7530\n",
            "Epoch 10/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4766 - accuracy: 0.7679 - val_loss: 0.4957 - val_accuracy: 0.7521\n",
            "Epoch 11/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4754 - accuracy: 0.7672 - val_loss: 0.4938 - val_accuracy: 0.7571\n",
            "Epoch 12/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4743 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7527\n",
            "Epoch 13/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4734 - accuracy: 0.7685 - val_loss: 0.4902 - val_accuracy: 0.7546\n",
            "Epoch 14/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4720 - accuracy: 0.7699 - val_loss: 0.4938 - val_accuracy: 0.7545\n",
            "Epoch 15/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4715 - accuracy: 0.7699 - val_loss: 0.4938 - val_accuracy: 0.7556\n",
            "Epoch 16/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4703 - accuracy: 0.7720 - val_loss: 0.4941 - val_accuracy: 0.7551\n",
            "Epoch 17/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4693 - accuracy: 0.7703 - val_loss: 0.4917 - val_accuracy: 0.7551\n",
            "Epoch 18/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4687 - accuracy: 0.7728 - val_loss: 0.4964 - val_accuracy: 0.7536\n",
            "Epoch 19/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4682 - accuracy: 0.7721 - val_loss: 0.4984 - val_accuracy: 0.7536\n",
            "Epoch 20/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4673 - accuracy: 0.7715 - val_loss: 0.4957 - val_accuracy: 0.7530\n",
            "Epoch 21/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4658 - accuracy: 0.7736 - val_loss: 0.4976 - val_accuracy: 0.7543\n",
            "Epoch 22/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4650 - accuracy: 0.7748 - val_loss: 0.4959 - val_accuracy: 0.7534\n",
            "Epoch 23/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4638 - accuracy: 0.7749 - val_loss: 0.4988 - val_accuracy: 0.7548\n",
            "Epoch 24/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4631 - accuracy: 0.7742 - val_loss: 0.5038 - val_accuracy: 0.7536\n",
            "Epoch 25/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4624 - accuracy: 0.7757 - val_loss: 0.5105 - val_accuracy: 0.7538\n",
            "Epoch 26/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4616 - accuracy: 0.7758 - val_loss: 0.5043 - val_accuracy: 0.7544\n",
            "Epoch 27/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4610 - accuracy: 0.7757 - val_loss: 0.4978 - val_accuracy: 0.7590\n",
            "Epoch 28/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4600 - accuracy: 0.7761 - val_loss: 0.5050 - val_accuracy: 0.7572\n",
            "Epoch 29/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4593 - accuracy: 0.7768 - val_loss: 0.5063 - val_accuracy: 0.7571\n",
            "Epoch 30/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4588 - accuracy: 0.7766 - val_loss: 0.5028 - val_accuracy: 0.7574\n",
            "Epoch 31/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4582 - accuracy: 0.7783 - val_loss: 0.5118 - val_accuracy: 0.7569\n",
            "Epoch 32/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4573 - accuracy: 0.7784 - val_loss: 0.5076 - val_accuracy: 0.7527\n",
            "Epoch 33/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4559 - accuracy: 0.7780 - val_loss: 0.5126 - val_accuracy: 0.7565\n",
            "Epoch 34/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4550 - accuracy: 0.7790 - val_loss: 0.5159 - val_accuracy: 0.7528\n",
            "Epoch 35/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4546 - accuracy: 0.7797 - val_loss: 0.5207 - val_accuracy: 0.7559\n",
            "Epoch 36/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4535 - accuracy: 0.7794 - val_loss: 0.5200 - val_accuracy: 0.7567\n",
            "Epoch 37/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4541 - accuracy: 0.7803 - val_loss: 0.5291 - val_accuracy: 0.7558\n",
            "Epoch 38/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4534 - accuracy: 0.7805 - val_loss: 0.5196 - val_accuracy: 0.7566\n",
            "Epoch 39/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4521 - accuracy: 0.7794 - val_loss: 0.5244 - val_accuracy: 0.7563\n",
            "Epoch 40/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4522 - accuracy: 0.7806 - val_loss: 0.5274 - val_accuracy: 0.7572\n",
            "Epoch 41/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4510 - accuracy: 0.7814 - val_loss: 0.5357 - val_accuracy: 0.7573\n",
            "Epoch 42/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4501 - accuracy: 0.7825 - val_loss: 0.5405 - val_accuracy: 0.7572\n",
            "Epoch 43/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4501 - accuracy: 0.7823 - val_loss: 0.5398 - val_accuracy: 0.7578\n",
            "Epoch 44/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4493 - accuracy: 0.7814 - val_loss: 0.5331 - val_accuracy: 0.7576\n",
            "Epoch 45/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4485 - accuracy: 0.7824 - val_loss: 0.5407 - val_accuracy: 0.7567\n",
            "Epoch 46/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4485 - accuracy: 0.7827 - val_loss: 0.5426 - val_accuracy: 0.7581\n",
            "Epoch 47/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4492 - accuracy: 0.7832 - val_loss: 0.5297 - val_accuracy: 0.7573\n",
            "Epoch 48/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4476 - accuracy: 0.7821 - val_loss: 0.5453 - val_accuracy: 0.7598\n",
            "Epoch 49/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4472 - accuracy: 0.7832 - val_loss: 0.5380 - val_accuracy: 0.7566\n",
            "Epoch 50/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4467 - accuracy: 0.7833 - val_loss: 0.5426 - val_accuracy: 0.7577\n",
            "Epoch 51/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4455 - accuracy: 0.7838 - val_loss: 0.5484 - val_accuracy: 0.7564\n",
            "Epoch 52/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4477 - accuracy: 0.7819 - val_loss: 0.5339 - val_accuracy: 0.7584\n",
            "Epoch 53/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4450 - accuracy: 0.7838 - val_loss: 0.5433 - val_accuracy: 0.7558\n",
            "Epoch 54/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4450 - accuracy: 0.7842 - val_loss: 0.5680 - val_accuracy: 0.7570\n",
            "Epoch 55/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4443 - accuracy: 0.7834 - val_loss: 0.5498 - val_accuracy: 0.7572\n",
            "Epoch 56/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4437 - accuracy: 0.7846 - val_loss: 0.5510 - val_accuracy: 0.7571\n",
            "Epoch 57/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.5538 - val_accuracy: 0.7574\n",
            "Epoch 58/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4434 - accuracy: 0.7843 - val_loss: 0.5713 - val_accuracy: 0.7573\n",
            "Epoch 59/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4464 - accuracy: 0.7847 - val_loss: 0.5754 - val_accuracy: 0.7576\n",
            "Epoch 60/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4462 - accuracy: 0.7861 - val_loss: 0.5517 - val_accuracy: 0.7581\n",
            "Epoch 61/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4416 - accuracy: 0.7861 - val_loss: 0.5729 - val_accuracy: 0.7563\n",
            "Epoch 62/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4422 - accuracy: 0.7855 - val_loss: 0.5557 - val_accuracy: 0.7584\n",
            "Epoch 63/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4414 - accuracy: 0.7851 - val_loss: 0.5783 - val_accuracy: 0.7563\n",
            "Epoch 64/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4414 - accuracy: 0.7851 - val_loss: 0.5495 - val_accuracy: 0.7567\n",
            "Epoch 65/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4404 - accuracy: 0.7844 - val_loss: 0.5772 - val_accuracy: 0.7585\n",
            "Epoch 66/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4413 - accuracy: 0.7851 - val_loss: 0.5632 - val_accuracy: 0.7566\n",
            "Epoch 67/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4421 - accuracy: 0.7857 - val_loss: 0.5426 - val_accuracy: 0.7558\n",
            "Epoch 68/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4403 - accuracy: 0.7863 - val_loss: 0.5514 - val_accuracy: 0.7586\n",
            "Epoch 69/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4385 - accuracy: 0.7855 - val_loss: 0.5601 - val_accuracy: 0.7591\n",
            "Epoch 70/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4390 - accuracy: 0.7856 - val_loss: 0.5824 - val_accuracy: 0.7567\n",
            "Epoch 71/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4405 - accuracy: 0.7858 - val_loss: 0.5615 - val_accuracy: 0.7567\n",
            "Epoch 72/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4379 - accuracy: 0.7867 - val_loss: 0.5707 - val_accuracy: 0.7560\n",
            "Epoch 73/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4382 - accuracy: 0.7858 - val_loss: 0.5577 - val_accuracy: 0.7562\n",
            "Epoch 74/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4384 - accuracy: 0.7872 - val_loss: 0.5711 - val_accuracy: 0.7565\n",
            "Epoch 75/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4379 - accuracy: 0.7871 - val_loss: 0.5908 - val_accuracy: 0.7579\n",
            "Epoch 76/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4375 - accuracy: 0.7868 - val_loss: 0.5904 - val_accuracy: 0.7562\n",
            "Epoch 77/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4366 - accuracy: 0.7868 - val_loss: 0.5706 - val_accuracy: 0.7569\n",
            "Epoch 78/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4380 - accuracy: 0.7865 - val_loss: 0.5756 - val_accuracy: 0.7566\n",
            "Epoch 79/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4358 - accuracy: 0.7878 - val_loss: 0.5940 - val_accuracy: 0.7557\n",
            "Epoch 80/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4368 - accuracy: 0.7876 - val_loss: 0.5839 - val_accuracy: 0.7579\n",
            "Epoch 81/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4362 - accuracy: 0.7879 - val_loss: 0.6112 - val_accuracy: 0.7594\n",
            "Epoch 82/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4372 - accuracy: 0.7861 - val_loss: 0.5810 - val_accuracy: 0.7573\n",
            "Epoch 83/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4358 - accuracy: 0.7874 - val_loss: 0.6132 - val_accuracy: 0.7558\n",
            "Epoch 84/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4349 - accuracy: 0.7879 - val_loss: 0.6022 - val_accuracy: 0.7559\n",
            "Epoch 85/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4344 - accuracy: 0.7874 - val_loss: 0.6122 - val_accuracy: 0.7563\n",
            "Epoch 86/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4345 - accuracy: 0.7881 - val_loss: 0.6271 - val_accuracy: 0.7551\n",
            "Epoch 87/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4350 - accuracy: 0.7880 - val_loss: 0.5928 - val_accuracy: 0.7586\n",
            "Epoch 88/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4357 - accuracy: 0.7879 - val_loss: 0.6088 - val_accuracy: 0.7577\n",
            "Epoch 89/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4345 - accuracy: 0.7882 - val_loss: 0.6240 - val_accuracy: 0.7595\n",
            "Epoch 90/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4337 - accuracy: 0.7879 - val_loss: 0.6277 - val_accuracy: 0.7574\n",
            "Epoch 91/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4345 - accuracy: 0.7885 - val_loss: 0.6043 - val_accuracy: 0.7607\n",
            "Epoch 92/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4338 - accuracy: 0.7879 - val_loss: 0.6123 - val_accuracy: 0.7552\n",
            "Epoch 93/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4328 - accuracy: 0.7891 - val_loss: 0.6332 - val_accuracy: 0.7555\n",
            "Epoch 94/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4330 - accuracy: 0.7895 - val_loss: 0.6065 - val_accuracy: 0.7557\n",
            "Epoch 95/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4326 - accuracy: 0.7886 - val_loss: 0.5959 - val_accuracy: 0.7584\n",
            "Epoch 96/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4325 - accuracy: 0.7887 - val_loss: 0.6185 - val_accuracy: 0.7570\n",
            "Epoch 97/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4335 - accuracy: 0.7886 - val_loss: 0.6209 - val_accuracy: 0.7557\n",
            "Epoch 98/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4339 - accuracy: 0.7884 - val_loss: 0.6054 - val_accuracy: 0.7599\n",
            "Epoch 99/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4346 - accuracy: 0.7888 - val_loss: 0.6203 - val_accuracy: 0.7581\n",
            "Epoch 100/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4312 - accuracy: 0.7887 - val_loss: 0.6170 - val_accuracy: 0.7558\n",
            "Epoch 101/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4331 - accuracy: 0.7891 - val_loss: 0.6050 - val_accuracy: 0.7586\n",
            "Epoch 102/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4327 - accuracy: 0.7886 - val_loss: 0.6084 - val_accuracy: 0.7576\n",
            "Epoch 103/150\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.4336 - accuracy: 0.7884 - val_loss: 0.6232 - val_accuracy: 0.7569\n",
            "Epoch 104/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4308 - accuracy: 0.7903 - val_loss: 0.6343 - val_accuracy: 0.7557\n",
            "Epoch 105/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4315 - accuracy: 0.7888 - val_loss: 0.6134 - val_accuracy: 0.7562\n",
            "Epoch 106/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4303 - accuracy: 0.7891 - val_loss: 0.6300 - val_accuracy: 0.7563\n",
            "Epoch 107/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4308 - accuracy: 0.7907 - val_loss: 0.6457 - val_accuracy: 0.7580\n",
            "Epoch 108/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4309 - accuracy: 0.7891 - val_loss: 0.6384 - val_accuracy: 0.7576\n",
            "Epoch 109/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4297 - accuracy: 0.7904 - val_loss: 0.6592 - val_accuracy: 0.7556\n",
            "Epoch 110/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4298 - accuracy: 0.7896 - val_loss: 0.6744 - val_accuracy: 0.7581\n",
            "Epoch 111/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4306 - accuracy: 0.7898 - val_loss: 0.6664 - val_accuracy: 0.7553\n",
            "Epoch 112/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4305 - accuracy: 0.7893 - val_loss: 0.6392 - val_accuracy: 0.7557\n",
            "Epoch 113/150\n",
            "804/804 [==============================] - 4s 6ms/step - loss: 0.4290 - accuracy: 0.7903 - val_loss: 0.6602 - val_accuracy: 0.7558\n",
            "Epoch 114/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4291 - accuracy: 0.7904 - val_loss: 0.6580 - val_accuracy: 0.7572\n",
            "Epoch 115/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4303 - accuracy: 0.7894 - val_loss: 0.6436 - val_accuracy: 0.7573\n",
            "Epoch 116/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4298 - accuracy: 0.7901 - val_loss: 0.6590 - val_accuracy: 0.7576\n",
            "Epoch 117/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4287 - accuracy: 0.7908 - val_loss: 0.6972 - val_accuracy: 0.7549\n",
            "Epoch 118/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4309 - accuracy: 0.7896 - val_loss: 0.6903 - val_accuracy: 0.7556\n",
            "Epoch 119/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4272 - accuracy: 0.7918 - val_loss: 0.6764 - val_accuracy: 0.7545\n",
            "Epoch 120/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4296 - accuracy: 0.7902 - val_loss: 0.6258 - val_accuracy: 0.7572\n",
            "Epoch 121/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4293 - accuracy: 0.7901 - val_loss: 0.6590 - val_accuracy: 0.7560\n",
            "Epoch 122/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4283 - accuracy: 0.7919 - val_loss: 0.6403 - val_accuracy: 0.7559\n",
            "Epoch 123/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4275 - accuracy: 0.7904 - val_loss: 0.6490 - val_accuracy: 0.7565\n",
            "Epoch 124/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4276 - accuracy: 0.7916 - val_loss: 0.6434 - val_accuracy: 0.7574\n",
            "Epoch 125/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4280 - accuracy: 0.7907 - val_loss: 0.6473 - val_accuracy: 0.7551\n",
            "Epoch 126/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4280 - accuracy: 0.7915 - val_loss: 0.6764 - val_accuracy: 0.7572\n",
            "Epoch 127/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4308 - accuracy: 0.7915 - val_loss: 0.6609 - val_accuracy: 0.7550\n",
            "Epoch 128/150\n",
            "804/804 [==============================] - 4s 6ms/step - loss: 0.4296 - accuracy: 0.7897 - val_loss: 0.6527 - val_accuracy: 0.7555\n",
            "Epoch 129/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4267 - accuracy: 0.7914 - val_loss: 0.6737 - val_accuracy: 0.7555\n",
            "Epoch 130/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4271 - accuracy: 0.7909 - val_loss: 0.6729 - val_accuracy: 0.7539\n",
            "Epoch 131/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4257 - accuracy: 0.7913 - val_loss: 0.7406 - val_accuracy: 0.7556\n",
            "Epoch 132/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4267 - accuracy: 0.7916 - val_loss: 0.6568 - val_accuracy: 0.7564\n",
            "Epoch 133/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4287 - accuracy: 0.7906 - val_loss: 0.6877 - val_accuracy: 0.7535\n",
            "Epoch 134/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4274 - accuracy: 0.7923 - val_loss: 0.7056 - val_accuracy: 0.7563\n",
            "Epoch 135/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4280 - accuracy: 0.7904 - val_loss: 0.6475 - val_accuracy: 0.7546\n",
            "Epoch 136/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4263 - accuracy: 0.7906 - val_loss: 0.6869 - val_accuracy: 0.7557\n",
            "Epoch 137/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4261 - accuracy: 0.7930 - val_loss: 0.6762 - val_accuracy: 0.7556\n",
            "Epoch 138/150\n",
            "804/804 [==============================] - 6s 7ms/step - loss: 0.4266 - accuracy: 0.7911 - val_loss: 0.6625 - val_accuracy: 0.7567\n",
            "Epoch 139/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4254 - accuracy: 0.7912 - val_loss: 0.6728 - val_accuracy: 0.7552\n",
            "Epoch 140/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4257 - accuracy: 0.7933 - val_loss: 0.7039 - val_accuracy: 0.7539\n",
            "Epoch 141/150\n",
            "804/804 [==============================] - 5s 7ms/step - loss: 0.4264 - accuracy: 0.7912 - val_loss: 0.6812 - val_accuracy: 0.7534\n",
            "Epoch 142/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4264 - accuracy: 0.7916 - val_loss: 0.6598 - val_accuracy: 0.7567\n",
            "Epoch 143/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4252 - accuracy: 0.7919 - val_loss: 0.6846 - val_accuracy: 0.7559\n",
            "Epoch 144/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4298 - accuracy: 0.7920 - val_loss: 0.6874 - val_accuracy: 0.7581\n",
            "Epoch 145/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4251 - accuracy: 0.7913 - val_loss: 0.7095 - val_accuracy: 0.7550\n",
            "Epoch 146/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4243 - accuracy: 0.7922 - val_loss: 0.7048 - val_accuracy: 0.7566\n",
            "Epoch 147/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4243 - accuracy: 0.7930 - val_loss: 0.7152 - val_accuracy: 0.7535\n",
            "Epoch 148/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4238 - accuracy: 0.7922 - val_loss: 0.7283 - val_accuracy: 0.7560\n",
            "Epoch 149/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4257 - accuracy: 0.7922 - val_loss: 0.7311 - val_accuracy: 0.7560\n",
            "Epoch 150/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4257 - accuracy: 0.7924 - val_loss: 0.6888 - val_accuracy: 0.7539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKwRd6USsGJg",
        "outputId": "dc8d43b5-6ad9-4548-af2e-1b7f1000ca37"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.7539\n",
            "Loss: 0.6888048648834229, Accuracy: 0.7539358735084534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_df = pd.DataFrame(fit_model.history)\n",
        "history_df.index += 1\n",
        "history_df.plot(y=\"accuracy\",title=\"Optimization Attempt 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "roFJi9K9wXji",
        "outputId": "cd4c7b09-3732-4e91-f2cf-bbafa423e6ac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn2.save('AlphabetSoupCharity_Optimisation2.h5')"
      ],
      "metadata": {
        "id": "cRGx5b5C8-6f"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OPTIMIZATION MODEL 3 (REVISED BINS, REDUCED INPUT FEATURES, MAXIMUM NEURONS, INCREASED EPOCHS)\n",
        "reduced_df=application_df.drop(columns=['CLASSIFICATION',\"SPECIAL_CONSIDERATIONS\"])\n",
        "reduced_dummy_cats = ['NAME','AFFILIATION','APPLICATION_TYPE','STATUS','USE_CASE','ORGANIZATION','INCOME_AMT']\n",
        "reduced_dummies = pd.get_dummies(reduced_df, columns = reduced_dummy_cats)\n",
        "reduced_dummies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "m0Tu8sL09EUy",
        "outputId": "9ef502b7-a3d4-49ca-c0f7-9920b9939064"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             EIN   ASK_AMT  IS_SUCCESSFUL  NAME_ALPHA PHI SIGMA  \\\n",
              "0       10520599      5000              1                     0   \n",
              "1       10531628    108590              1                     0   \n",
              "2       10547893      5000              0                     0   \n",
              "3       10553066      6692              1                     0   \n",
              "4       10556103    142590              1                     0   \n",
              "...          ...       ...            ...                   ...   \n",
              "34294  996009318      5000              0                     0   \n",
              "34295  996010315      5000              0                     0   \n",
              "34296  996012607      5000              0                     0   \n",
              "34297  996015768      5000              1                     0   \n",
              "34298  996086871  36500179              0                     0   \n",
              "\n",
              "       NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC  \\\n",
              "0                                                      0      \n",
              "1                                                      0      \n",
              "2                                                      0      \n",
              "3                                                      0      \n",
              "4                                                      0      \n",
              "...                                                  ...      \n",
              "34294                                                  0      \n",
              "34295                                                  0      \n",
              "34296                                                  0      \n",
              "34297                                                  0      \n",
              "34298                                                  0      \n",
              "\n",
              "       NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN  \\\n",
              "0                                                  0   \n",
              "1                                                  0   \n",
              "2                                                  0   \n",
              "3                                                  0   \n",
              "4                                                  0   \n",
              "...                                              ...   \n",
              "34294                                              0   \n",
              "34295                                              0   \n",
              "34296                                              0   \n",
              "34297                                              0   \n",
              "34298                                              0   \n",
              "\n",
              "       NAME_CIVITAN INTERNATIONAL  NAME_DEMOLAY INTERNATIONAL  \\\n",
              "0                               0                           0   \n",
              "1                               0                           0   \n",
              "2                               0                           0   \n",
              "3                               0                           0   \n",
              "4                               0                           0   \n",
              "...                           ...                         ...   \n",
              "34294                           0                           0   \n",
              "34295                           0                           0   \n",
              "34296                           0                           0   \n",
              "34297                           0                           0   \n",
              "34298                           0                           0   \n",
              "\n",
              "       NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA  \\\n",
              "0                                                      0           \n",
              "1                                                      0           \n",
              "2                                                      0           \n",
              "3                                                      0           \n",
              "4                                                      0           \n",
              "...                                                  ...           \n",
              "34294                                                  0           \n",
              "34295                                                  0           \n",
              "34296                                                  0           \n",
              "34297                                                  0           \n",
              "34298                                                  0           \n",
              "\n",
              "       NAME_HABITAT FOR HUMANITY INTERNATIONAL INC  ...  ORGANIZATION_Trust  \\\n",
              "0                                                0  ...                   0   \n",
              "1                                                0  ...                   0   \n",
              "2                                                0  ...                   0   \n",
              "3                                                0  ...                   1   \n",
              "4                                                0  ...                   1   \n",
              "...                                            ...  ...                 ...   \n",
              "34294                                            0  ...                   0   \n",
              "34295                                            0  ...                   0   \n",
              "34296                                            0  ...                   0   \n",
              "34297                                            0  ...                   0   \n",
              "34298                                            0  ...                   0   \n",
              "\n",
              "       INCOME_AMT_0  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
              "0                 1                  0                       0   \n",
              "1                 0                  1                       0   \n",
              "2                 1                  0                       0   \n",
              "3                 0                  0                       1   \n",
              "4                 0                  0                       0   \n",
              "...             ...                ...                     ...   \n",
              "34294             1                  0                       0   \n",
              "34295             1                  0                       0   \n",
              "34296             1                  0                       0   \n",
              "34297             1                  0                       0   \n",
              "34298             0                  0                       0   \n",
              "\n",
              "       INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
              "0                             0                   0                 0   \n",
              "1                             0                   0                 0   \n",
              "2                             0                   0                 0   \n",
              "3                             0                   0                 0   \n",
              "4                             1                   0                 0   \n",
              "...                         ...                 ...               ...   \n",
              "34294                         0                   0                 0   \n",
              "34295                         0                   0                 0   \n",
              "34296                         0                   0                 0   \n",
              "34297                         0                   0                 0   \n",
              "34298                         0                   0                 1   \n",
              "\n",
              "       INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \n",
              "0                           0                0                  0  \n",
              "1                           0                0                  0  \n",
              "2                           0                0                  0  \n",
              "3                           0                0                  0  \n",
              "4                           0                0                  0  \n",
              "...                       ...              ...                ...  \n",
              "34294                       0                0                  0  \n",
              "34295                       0                0                  0  \n",
              "34296                       0                0                  0  \n",
              "34297                       0                0                  0  \n",
              "34298                       0                0                  0  \n",
              "\n",
              "[34299 rows x 73 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffa44945-678b-4749-98c4-1f0a52925169\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>NAME_ALPHA PHI SIGMA</th>\n",
              "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
              "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
              "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
              "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
              "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
              "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
              "      <th>...</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>996009318</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>996010315</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>996012607</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>996015768</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>996086871</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows Ã— 73 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffa44945-678b-4749-98c4-1f0a52925169')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffa44945-678b-4749-98c4-1f0a52925169 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffa44945-678b-4749-98c4-1f0a52925169');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splits our preprocessed data into our features and target arrays\n",
        "y = reduced_dummies['IS_SUCCESSFUL'].values\n",
        "X = reduced_dummies.drop(columns=\"IS_SUCCESSFUL\").values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n",
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Pe5YTPYGBXr8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer_1= 3*number_input_features\n",
        "hidden_nodes_layer_2 = 3*number_input_features\n",
        "hidden_nodes_layer_3 = 3*number_input_features\n",
        "\n",
        "nn3 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn3.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer_1, input_dim=number_input_features, activation=\"ReLU\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer_2, activation=\"ReLU\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer_3, activation=\"ReLU\"))\n",
        "\n",
        "# Output layer\n",
        "nn3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE2OMkW9EbuG",
        "outputId": "cdd76bcc-fd5a-411c-cebd-4f1c00542dab"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 216)               15768     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 216)               46872     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 216)               46872     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 217       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,729\n",
            "Trainable params: 109,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiles the model\n",
        "nn3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZazBrgFdE3Ir"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = nn3.fit(X_train_scaled,y_train,epochs=150, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZJnw4_4FEys",
        "outputId": "27b73a8e-ae63-462a-df81-90b415e434f1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "804/804 [==============================] - 5s 4ms/step - loss: 0.5175 - accuracy: 0.7378 - val_loss: 0.5147 - val_accuracy: 0.7364\n",
            "Epoch 2/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5045 - accuracy: 0.7437 - val_loss: 0.5125 - val_accuracy: 0.7383\n",
            "Epoch 3/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5010 - accuracy: 0.7463 - val_loss: 0.5066 - val_accuracy: 0.7390\n",
            "Epoch 4/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.5000 - accuracy: 0.7462 - val_loss: 0.5062 - val_accuracy: 0.7410\n",
            "Epoch 5/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4986 - accuracy: 0.7463 - val_loss: 0.5081 - val_accuracy: 0.7383\n",
            "Epoch 6/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4981 - accuracy: 0.7483 - val_loss: 0.5057 - val_accuracy: 0.7401\n",
            "Epoch 7/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4966 - accuracy: 0.7475 - val_loss: 0.5080 - val_accuracy: 0.7425\n",
            "Epoch 8/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4964 - accuracy: 0.7495 - val_loss: 0.5061 - val_accuracy: 0.7418\n",
            "Epoch 9/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4958 - accuracy: 0.7503 - val_loss: 0.5063 - val_accuracy: 0.7434\n",
            "Epoch 10/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4941 - accuracy: 0.7490 - val_loss: 0.5057 - val_accuracy: 0.7399\n",
            "Epoch 11/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4944 - accuracy: 0.7498 - val_loss: 0.5060 - val_accuracy: 0.7412\n",
            "Epoch 12/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4928 - accuracy: 0.7521 - val_loss: 0.5090 - val_accuracy: 0.7406\n",
            "Epoch 13/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4930 - accuracy: 0.7511 - val_loss: 0.5100 - val_accuracy: 0.7420\n",
            "Epoch 14/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4921 - accuracy: 0.7524 - val_loss: 0.5118 - val_accuracy: 0.7338\n",
            "Epoch 15/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4914 - accuracy: 0.7531 - val_loss: 0.5089 - val_accuracy: 0.7474\n",
            "Epoch 16/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4909 - accuracy: 0.7533 - val_loss: 0.5065 - val_accuracy: 0.7459\n",
            "Epoch 17/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4897 - accuracy: 0.7550 - val_loss: 0.5114 - val_accuracy: 0.7439\n",
            "Epoch 18/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4901 - accuracy: 0.7544 - val_loss: 0.5100 - val_accuracy: 0.7437\n",
            "Epoch 19/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4888 - accuracy: 0.7545 - val_loss: 0.5146 - val_accuracy: 0.7430\n",
            "Epoch 20/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4885 - accuracy: 0.7555 - val_loss: 0.5122 - val_accuracy: 0.7438\n",
            "Epoch 21/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4886 - accuracy: 0.7547 - val_loss: 0.5101 - val_accuracy: 0.7418\n",
            "Epoch 22/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4877 - accuracy: 0.7562 - val_loss: 0.5131 - val_accuracy: 0.7417\n",
            "Epoch 23/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4873 - accuracy: 0.7561 - val_loss: 0.5105 - val_accuracy: 0.7445\n",
            "Epoch 24/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4871 - accuracy: 0.7570 - val_loss: 0.5138 - val_accuracy: 0.7438\n",
            "Epoch 25/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4869 - accuracy: 0.7551 - val_loss: 0.5144 - val_accuracy: 0.7420\n",
            "Epoch 26/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4861 - accuracy: 0.7569 - val_loss: 0.5107 - val_accuracy: 0.7430\n",
            "Epoch 27/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4854 - accuracy: 0.7568 - val_loss: 0.5139 - val_accuracy: 0.7416\n",
            "Epoch 28/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4844 - accuracy: 0.7573 - val_loss: 0.5225 - val_accuracy: 0.7433\n",
            "Epoch 29/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4843 - accuracy: 0.7582 - val_loss: 0.5278 - val_accuracy: 0.7443\n",
            "Epoch 30/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4839 - accuracy: 0.7586 - val_loss: 0.5183 - val_accuracy: 0.7436\n",
            "Epoch 31/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4829 - accuracy: 0.7586 - val_loss: 0.5262 - val_accuracy: 0.7454\n",
            "Epoch 32/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4826 - accuracy: 0.7581 - val_loss: 0.5171 - val_accuracy: 0.7422\n",
            "Epoch 33/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4822 - accuracy: 0.7592 - val_loss: 0.5174 - val_accuracy: 0.7415\n",
            "Epoch 34/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4816 - accuracy: 0.7608 - val_loss: 0.5263 - val_accuracy: 0.7444\n",
            "Epoch 35/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4814 - accuracy: 0.7593 - val_loss: 0.5228 - val_accuracy: 0.7461\n",
            "Epoch 36/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4813 - accuracy: 0.7596 - val_loss: 0.5169 - val_accuracy: 0.7445\n",
            "Epoch 37/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4812 - accuracy: 0.7599 - val_loss: 0.5202 - val_accuracy: 0.7446\n",
            "Epoch 38/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4798 - accuracy: 0.7610 - val_loss: 0.5267 - val_accuracy: 0.7454\n",
            "Epoch 39/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4797 - accuracy: 0.7596 - val_loss: 0.5328 - val_accuracy: 0.7424\n",
            "Epoch 40/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4794 - accuracy: 0.7611 - val_loss: 0.5351 - val_accuracy: 0.7459\n",
            "Epoch 41/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4826 - accuracy: 0.7612 - val_loss: 0.5325 - val_accuracy: 0.7415\n",
            "Epoch 42/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4782 - accuracy: 0.7613 - val_loss: 0.5396 - val_accuracy: 0.7448\n",
            "Epoch 43/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4781 - accuracy: 0.7621 - val_loss: 0.5295 - val_accuracy: 0.7440\n",
            "Epoch 44/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4782 - accuracy: 0.7618 - val_loss: 0.5402 - val_accuracy: 0.7460\n",
            "Epoch 45/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4778 - accuracy: 0.7610 - val_loss: 0.5447 - val_accuracy: 0.7444\n",
            "Epoch 46/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4785 - accuracy: 0.7625 - val_loss: 0.5331 - val_accuracy: 0.7451\n",
            "Epoch 47/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4770 - accuracy: 0.7616 - val_loss: 0.5342 - val_accuracy: 0.7454\n",
            "Epoch 48/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4772 - accuracy: 0.7624 - val_loss: 0.5351 - val_accuracy: 0.7453\n",
            "Epoch 49/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4764 - accuracy: 0.7628 - val_loss: 0.5319 - val_accuracy: 0.7443\n",
            "Epoch 50/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4764 - accuracy: 0.7635 - val_loss: 0.5394 - val_accuracy: 0.7455\n",
            "Epoch 51/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4757 - accuracy: 0.7630 - val_loss: 0.5535 - val_accuracy: 0.7467\n",
            "Epoch 52/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4762 - accuracy: 0.7631 - val_loss: 0.5405 - val_accuracy: 0.7444\n",
            "Epoch 53/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4756 - accuracy: 0.7635 - val_loss: 0.5437 - val_accuracy: 0.7448\n",
            "Epoch 54/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4750 - accuracy: 0.7647 - val_loss: 0.5476 - val_accuracy: 0.7438\n",
            "Epoch 55/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4751 - accuracy: 0.7636 - val_loss: 0.5405 - val_accuracy: 0.7444\n",
            "Epoch 56/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4749 - accuracy: 0.7636 - val_loss: 0.5470 - val_accuracy: 0.7437\n",
            "Epoch 57/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4748 - accuracy: 0.7645 - val_loss: 0.5586 - val_accuracy: 0.7440\n",
            "Epoch 58/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4899 - accuracy: 0.7633 - val_loss: 0.5486 - val_accuracy: 0.7444\n",
            "Epoch 59/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4739 - accuracy: 0.7648 - val_loss: 0.5614 - val_accuracy: 0.7454\n",
            "Epoch 60/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4731 - accuracy: 0.7643 - val_loss: 0.5451 - val_accuracy: 0.7448\n",
            "Epoch 61/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4726 - accuracy: 0.7654 - val_loss: 0.5459 - val_accuracy: 0.7468\n",
            "Epoch 62/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4721 - accuracy: 0.7645 - val_loss: 0.5613 - val_accuracy: 0.7445\n",
            "Epoch 63/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4720 - accuracy: 0.7655 - val_loss: 0.5495 - val_accuracy: 0.7472\n",
            "Epoch 64/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4723 - accuracy: 0.7647 - val_loss: 0.5637 - val_accuracy: 0.7425\n",
            "Epoch 65/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4726 - accuracy: 0.7643 - val_loss: 0.5519 - val_accuracy: 0.7436\n",
            "Epoch 66/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4716 - accuracy: 0.7648 - val_loss: 0.5828 - val_accuracy: 0.7433\n",
            "Epoch 67/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4726 - accuracy: 0.7663 - val_loss: 0.5730 - val_accuracy: 0.7438\n",
            "Epoch 68/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4727 - accuracy: 0.7652 - val_loss: 0.5814 - val_accuracy: 0.7474\n",
            "Epoch 69/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4721 - accuracy: 0.7651 - val_loss: 0.5690 - val_accuracy: 0.7466\n",
            "Epoch 70/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4712 - accuracy: 0.7657 - val_loss: 0.5799 - val_accuracy: 0.7420\n",
            "Epoch 71/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4714 - accuracy: 0.7649 - val_loss: 0.5664 - val_accuracy: 0.7434\n",
            "Epoch 72/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4708 - accuracy: 0.7665 - val_loss: 0.5730 - val_accuracy: 0.7441\n",
            "Epoch 73/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4713 - accuracy: 0.7643 - val_loss: 0.5714 - val_accuracy: 0.7434\n",
            "Epoch 74/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4707 - accuracy: 0.7659 - val_loss: 0.5803 - val_accuracy: 0.7436\n",
            "Epoch 75/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4728 - accuracy: 0.7660 - val_loss: 0.5819 - val_accuracy: 0.7436\n",
            "Epoch 76/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.5999 - val_accuracy: 0.7424\n",
            "Epoch 77/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4703 - accuracy: 0.7664 - val_loss: 0.5754 - val_accuracy: 0.7448\n",
            "Epoch 78/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4695 - accuracy: 0.7669 - val_loss: 0.5893 - val_accuracy: 0.7447\n",
            "Epoch 79/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4699 - accuracy: 0.7666 - val_loss: 0.5916 - val_accuracy: 0.7444\n",
            "Epoch 80/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4688 - accuracy: 0.7661 - val_loss: 0.5829 - val_accuracy: 0.7445\n",
            "Epoch 81/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4697 - accuracy: 0.7660 - val_loss: 0.6069 - val_accuracy: 0.7425\n",
            "Epoch 82/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4689 - accuracy: 0.7668 - val_loss: 0.5787 - val_accuracy: 0.7427\n",
            "Epoch 83/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4686 - accuracy: 0.7672 - val_loss: 0.6255 - val_accuracy: 0.7444\n",
            "Epoch 84/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4691 - accuracy: 0.7668 - val_loss: 0.6111 - val_accuracy: 0.7419\n",
            "Epoch 85/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4694 - accuracy: 0.7669 - val_loss: 0.6020 - val_accuracy: 0.7460\n",
            "Epoch 86/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4691 - accuracy: 0.7670 - val_loss: 0.5705 - val_accuracy: 0.7452\n",
            "Epoch 87/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4704 - accuracy: 0.7675 - val_loss: 0.5949 - val_accuracy: 0.7452\n",
            "Epoch 88/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4676 - accuracy: 0.7680 - val_loss: 0.6035 - val_accuracy: 0.7429\n",
            "Epoch 89/150\n",
            "804/804 [==============================] - 4s 6ms/step - loss: 0.4673 - accuracy: 0.7667 - val_loss: 0.5800 - val_accuracy: 0.7443\n",
            "Epoch 90/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4670 - accuracy: 0.7677 - val_loss: 0.5963 - val_accuracy: 0.7429\n",
            "Epoch 91/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4670 - accuracy: 0.7676 - val_loss: 0.6010 - val_accuracy: 0.7464\n",
            "Epoch 92/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4677 - accuracy: 0.7672 - val_loss: 0.6085 - val_accuracy: 0.7433\n",
            "Epoch 93/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4668 - accuracy: 0.7677 - val_loss: 0.6008 - val_accuracy: 0.7434\n",
            "Epoch 94/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4668 - accuracy: 0.7680 - val_loss: 0.6588 - val_accuracy: 0.7423\n",
            "Epoch 95/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4920 - accuracy: 0.7681 - val_loss: 0.6031 - val_accuracy: 0.7441\n",
            "Epoch 96/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4686 - accuracy: 0.7683 - val_loss: 0.6238 - val_accuracy: 0.7433\n",
            "Epoch 97/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4659 - accuracy: 0.7679 - val_loss: 0.6312 - val_accuracy: 0.7440\n",
            "Epoch 98/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4657 - accuracy: 0.7680 - val_loss: 0.6632 - val_accuracy: 0.7443\n",
            "Epoch 99/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4666 - accuracy: 0.7671 - val_loss: 0.6542 - val_accuracy: 0.7402\n",
            "Epoch 100/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4674 - accuracy: 0.7679 - val_loss: 0.6243 - val_accuracy: 0.7436\n",
            "Epoch 101/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4652 - accuracy: 0.7682 - val_loss: 0.6527 - val_accuracy: 0.7432\n",
            "Epoch 102/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4659 - accuracy: 0.7688 - val_loss: 0.6293 - val_accuracy: 0.7438\n",
            "Epoch 103/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4656 - accuracy: 0.7688 - val_loss: 0.6417 - val_accuracy: 0.7441\n",
            "Epoch 104/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4649 - accuracy: 0.7680 - val_loss: 0.6613 - val_accuracy: 0.7457\n",
            "Epoch 105/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4659 - accuracy: 0.7689 - val_loss: 0.6567 - val_accuracy: 0.7427\n",
            "Epoch 106/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4669 - accuracy: 0.7684 - val_loss: 0.6415 - val_accuracy: 0.7422\n",
            "Epoch 107/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4651 - accuracy: 0.7678 - val_loss: 0.6650 - val_accuracy: 0.7427\n",
            "Epoch 108/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4648 - accuracy: 0.7680 - val_loss: 0.6547 - val_accuracy: 0.7436\n",
            "Epoch 109/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4649 - accuracy: 0.7683 - val_loss: 0.6767 - val_accuracy: 0.7445\n",
            "Epoch 110/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4644 - accuracy: 0.7677 - val_loss: 0.6273 - val_accuracy: 0.7436\n",
            "Epoch 111/150\n",
            "804/804 [==============================] - 4s 6ms/step - loss: 0.4646 - accuracy: 0.7687 - val_loss: 0.6679 - val_accuracy: 0.7433\n",
            "Epoch 112/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4643 - accuracy: 0.7684 - val_loss: 0.6809 - val_accuracy: 0.7416\n",
            "Epoch 113/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4649 - accuracy: 0.7688 - val_loss: 0.6671 - val_accuracy: 0.7413\n",
            "Epoch 114/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4644 - accuracy: 0.7692 - val_loss: 0.7397 - val_accuracy: 0.7446\n",
            "Epoch 115/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4650 - accuracy: 0.7685 - val_loss: 0.7152 - val_accuracy: 0.7417\n",
            "Epoch 116/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4705 - accuracy: 0.7685 - val_loss: 0.7218 - val_accuracy: 0.7439\n",
            "Epoch 117/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4637 - accuracy: 0.7687 - val_loss: 0.7466 - val_accuracy: 0.7431\n",
            "Epoch 118/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4638 - accuracy: 0.7698 - val_loss: 0.7289 - val_accuracy: 0.7427\n",
            "Epoch 119/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4647 - accuracy: 0.7687 - val_loss: 0.7302 - val_accuracy: 0.7439\n",
            "Epoch 120/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4649 - accuracy: 0.7682 - val_loss: 0.6981 - val_accuracy: 0.7420\n",
            "Epoch 121/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4644 - accuracy: 0.7699 - val_loss: 0.7566 - val_accuracy: 0.7436\n",
            "Epoch 122/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4636 - accuracy: 0.7700 - val_loss: 0.7572 - val_accuracy: 0.7438\n",
            "Epoch 123/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4629 - accuracy: 0.7697 - val_loss: 0.7012 - val_accuracy: 0.7423\n",
            "Epoch 124/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4639 - accuracy: 0.7694 - val_loss: 0.6973 - val_accuracy: 0.7448\n",
            "Epoch 125/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4648 - accuracy: 0.7685 - val_loss: 0.6837 - val_accuracy: 0.7446\n",
            "Epoch 126/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4638 - accuracy: 0.7689 - val_loss: 0.7198 - val_accuracy: 0.7433\n",
            "Epoch 127/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4643 - accuracy: 0.7691 - val_loss: 0.7174 - val_accuracy: 0.7429\n",
            "Epoch 128/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4637 - accuracy: 0.7685 - val_loss: 0.6937 - val_accuracy: 0.7430\n",
            "Epoch 129/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4628 - accuracy: 0.7689 - val_loss: 0.7180 - val_accuracy: 0.7418\n",
            "Epoch 130/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4637 - accuracy: 0.7701 - val_loss: 0.7177 - val_accuracy: 0.7439\n",
            "Epoch 131/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4637 - accuracy: 0.7703 - val_loss: 0.6886 - val_accuracy: 0.7443\n",
            "Epoch 132/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4627 - accuracy: 0.7709 - val_loss: 0.7647 - val_accuracy: 0.7440\n",
            "Epoch 133/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4620 - accuracy: 0.7696 - val_loss: 0.7569 - val_accuracy: 0.7437\n",
            "Epoch 134/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.5228 - accuracy: 0.7687 - val_loss: 0.6368 - val_accuracy: 0.7443\n",
            "Epoch 135/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4703 - accuracy: 0.7681 - val_loss: 0.6462 - val_accuracy: 0.7420\n",
            "Epoch 136/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4642 - accuracy: 0.7701 - val_loss: 0.6586 - val_accuracy: 0.7433\n",
            "Epoch 137/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4618 - accuracy: 0.7704 - val_loss: 0.6701 - val_accuracy: 0.7429\n",
            "Epoch 138/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4613 - accuracy: 0.7690 - val_loss: 0.7068 - val_accuracy: 0.7433\n",
            "Epoch 139/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4615 - accuracy: 0.7696 - val_loss: 0.7096 - val_accuracy: 0.7426\n",
            "Epoch 140/150\n",
            "804/804 [==============================] - 5s 6ms/step - loss: 0.4612 - accuracy: 0.7697 - val_loss: 0.6824 - val_accuracy: 0.7422\n",
            "Epoch 141/150\n",
            "804/804 [==============================] - 4s 4ms/step - loss: 0.4617 - accuracy: 0.7711 - val_loss: 0.6965 - val_accuracy: 0.7440\n",
            "Epoch 142/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4614 - accuracy: 0.7695 - val_loss: 0.7324 - val_accuracy: 0.7441\n",
            "Epoch 143/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4615 - accuracy: 0.7701 - val_loss: 0.7285 - val_accuracy: 0.7423\n",
            "Epoch 144/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4637 - accuracy: 0.7692 - val_loss: 0.6263 - val_accuracy: 0.7443\n",
            "Epoch 145/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4624 - accuracy: 0.7696 - val_loss: 0.6670 - val_accuracy: 0.7415\n",
            "Epoch 146/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4613 - accuracy: 0.7699 - val_loss: 0.6565 - val_accuracy: 0.7430\n",
            "Epoch 147/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4621 - accuracy: 0.7695 - val_loss: 0.6450 - val_accuracy: 0.7423\n",
            "Epoch 148/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4621 - accuracy: 0.7704 - val_loss: 0.6570 - val_accuracy: 0.7444\n",
            "Epoch 149/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4615 - accuracy: 0.7715 - val_loss: 0.7002 - val_accuracy: 0.7430\n",
            "Epoch 150/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4613 - accuracy: 0.7700 - val_loss: 0.6916 - val_accuracy: 0.7427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = nn3.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "id": "EJHw1og1HAAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ddc231-8f54-4020-f58a-f7dbdf6ad149"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.7427\n",
            "Loss: 0.6915854811668396, Accuracy: 0.7427405118942261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn3.save('AlphabetSoupCharity_Optimisation3.h5')"
      ],
      "metadata": {
        "id": "Pycdd0DWyUOB"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}