{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "ts0QzDvtKBcM",
        "outputId": "7c85399f-3326-4080-95e1-15ebed2c03db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9042863e-813a-4689-96cd-185b915079bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9042863e-813a-4689-96cd-185b915079bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9042863e-813a-4689-96cd-185b915079bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9042863e-813a-4689-96cd-185b915079bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd \n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dla-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app_counts=application_df['APPLICATION_TYPE'].value_counts()\n",
        "\n",
        "# uses the variable name `application_types_to_replace`\n",
        "max_app_counts = 15\n",
        "\n",
        "application_types_to_replace = app_counts[app_counts<max_app_counts].index.tolist()\n",
        "# Replaces in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsPycZsSSAVc",
        "outputId": "67b4818c-e824-4b76-ff71-924fb634f733"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "T9         156\n",
              "T13         66\n",
              "T12         27\n",
              "T2          16\n",
              "Other       11\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "# uses the variable name `classifications_to_replace`\n",
        "max_classcount = 25\n",
        "classifications_to_replace = class_counts[class_counts<max_classcount].index.tolist()\n",
        "# Replaces in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy4N6UybT_fr",
        "outputId": "70d3f832-95cf-4daf-cd4d-a42219deb20b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "Other      227\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "application_df['NAME'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02dljVHHp2x7",
        "outputId": "beccc085-b25d-4841-81c5-7cf0b8fbf8b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PARENT BOOSTER USA INC                                                  1260\n",
              "TOPS CLUB INC                                                            765\n",
              "UNITED STATES BOWLING CONGRESS INC                                       700\n",
              "WASHINGTON STATE UNIVERSITY                                              492\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                          408\n",
              "                                                                        ... \n",
              "ST LOUIS SLAM WOMENS FOOTBALL                                              1\n",
              "AIESEC ALUMNI IBEROAMERICA CORP                                            1\n",
              "WEALLBLEEDRED ORG INC                                                      1\n",
              "AMERICAN SOCIETY FOR STANDARDS IN MEDIUMSHIP & PSYCHICAL INVESTIGATI       1\n",
              "WATERHOUSE CHARITABLE TR                                                   1\n",
              "Name: NAME, Length: 19568, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_counts = application_df['NAME'].value_counts()\n",
        "max_namecount = 100\n",
        "names_to_replace = name_counts[name_counts<max_namecount].index.tolist()\n",
        "# Replaces in dataframe\n",
        "for nme in names_to_replace:\n",
        "    application_df['NAME'] = application_df['NAME'].replace(nme,\"Other\")\n",
        "    \n",
        "# Check to make sure binning was successful\n",
        "application_df['NAME'].value_counts()"
      ],
      "metadata": {
        "id": "NXpZWZ_MqNz3",
        "outputId": "6354219c-4433-4c46-ec99-01889884fb22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Other                                                                 25987\n",
              "PARENT BOOSTER USA INC                                                 1260\n",
              "TOPS CLUB INC                                                           765\n",
              "UNITED STATES BOWLING CONGRESS INC                                      700\n",
              "WASHINGTON STATE UNIVERSITY                                             492\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                         408\n",
              "PTA TEXAS CONGRESS                                                      368\n",
              "SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC                           331\n",
              "ALPHA PHI SIGMA                                                         313\n",
              "TOASTMASTERS INTERNATIONAL                                              293\n",
              "MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS                       287\n",
              "LITTLE LEAGUE BASEBALL INC                                              277\n",
              "INTERNATIONAL ASSOCIATION OF LIONS CLUBS                                266\n",
              "MOMS CLUB                                                               210\n",
              "INTERNATIONAL ASSOCIATION OF SHEET METAL AIR RAIL & TRANSPORTATION      206\n",
              "AMERICAN ASSOCIATION OF UNIVERSITY WOMEN                                197\n",
              "FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA                    166\n",
              "KNIGHTS OF COLUMBUS                                                     158\n",
              "HABITAT FOR HUMANITY INTERNATIONAL INC                                  154\n",
              "TENNESSEE ORDER OF THE EASTERN STAR                                     151\n",
              "VETERANS OF FOREIGN WARS OF THE UNITED STATES AUXILIARY                 144\n",
              "PTA UTAH CONGRESS                                                       140\n",
              "THE UNITED STATES PONY CLUBS INC                                        136\n",
              "CIVITAN INTERNATIONAL                                                   131\n",
              "SIGMA BETA DELTA INC                                                    127\n",
              "HONOR SOCIETY OF PHI KAPPA PHI                                          107\n",
              "MONTANA 4-H FOUNDATION INC                                              107\n",
              "WASHINGTON STATE GRANGE                                                 106\n",
              "UNIVERSITY OF WYOMING                                                   105\n",
              "DEMOLAY INTERNATIONAL                                                   104\n",
              "SERTOMA INC                                                             103\n",
              "Name: NAME, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converts categorical data to numeric with `pd.get_dummies`\n",
        "dummy_cats = ['NAME','APPLICATION_TYPE','AFFILIATION','CLASSIFICATION','USE_CASE','ORGANIZATION','STATUS','INCOME_AMT','SPECIAL_CONSIDERATIONS']\n",
        "dummies_df=pd.get_dummies(application_df, columns=dummy_cats)\n",
        "\n",
        "dummies_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "I0GTNeS2URQA",
        "outputId": "37c90017-3a6c-4653-db41-0f0395dbdf29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             EIN   ASK_AMT  IS_SUCCESSFUL  NAME_ALPHA PHI SIGMA  \\\n",
              "0       10520599      5000              1                     0   \n",
              "1       10531628    108590              1                     0   \n",
              "2       10547893      5000              0                     0   \n",
              "3       10553066      6692              1                     0   \n",
              "4       10556103    142590              1                     0   \n",
              "...          ...       ...            ...                   ...   \n",
              "34294  996009318      5000              0                     0   \n",
              "34295  996010315      5000              0                     0   \n",
              "34296  996012607      5000              0                     0   \n",
              "34297  996015768      5000              1                     0   \n",
              "34298  996086871  36500179              0                     0   \n",
              "\n",
              "       NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC  \\\n",
              "0                                                      0      \n",
              "1                                                      0      \n",
              "2                                                      0      \n",
              "3                                                      0      \n",
              "4                                                      0      \n",
              "...                                                  ...      \n",
              "34294                                                  0      \n",
              "34295                                                  0      \n",
              "34296                                                  0      \n",
              "34297                                                  0      \n",
              "34298                                                  0      \n",
              "\n",
              "       NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN  \\\n",
              "0                                                  0   \n",
              "1                                                  0   \n",
              "2                                                  0   \n",
              "3                                                  0   \n",
              "4                                                  0   \n",
              "...                                              ...   \n",
              "34294                                              0   \n",
              "34295                                              0   \n",
              "34296                                              0   \n",
              "34297                                              0   \n",
              "34298                                              0   \n",
              "\n",
              "       NAME_CIVITAN INTERNATIONAL  NAME_DEMOLAY INTERNATIONAL  \\\n",
              "0                               0                           0   \n",
              "1                               0                           0   \n",
              "2                               0                           0   \n",
              "3                               0                           0   \n",
              "4                               0                           0   \n",
              "...                           ...                         ...   \n",
              "34294                           0                           0   \n",
              "34295                           0                           0   \n",
              "34296                           0                           0   \n",
              "34297                           0                           0   \n",
              "34298                           0                           0   \n",
              "\n",
              "       NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA  \\\n",
              "0                                                      0           \n",
              "1                                                      0           \n",
              "2                                                      0           \n",
              "3                                                      0           \n",
              "4                                                      0           \n",
              "...                                                  ...           \n",
              "34294                                                  0           \n",
              "34295                                                  0           \n",
              "34296                                                  0           \n",
              "34297                                                  0           \n",
              "34298                                                  0           \n",
              "\n",
              "       NAME_HABITAT FOR HUMANITY INTERNATIONAL INC  ...  INCOME_AMT_1-9999  \\\n",
              "0                                                0  ...                  0   \n",
              "1                                                0  ...                  1   \n",
              "2                                                0  ...                  0   \n",
              "3                                                0  ...                  0   \n",
              "4                                                0  ...                  0   \n",
              "...                                            ...  ...                ...   \n",
              "34294                                            0  ...                  0   \n",
              "34295                                            0  ...                  0   \n",
              "34296                                            0  ...                  0   \n",
              "34297                                            0  ...                  0   \n",
              "34298                                            0  ...                  0   \n",
              "\n",
              "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
              "0                           0                         0                   0   \n",
              "1                           0                         0                   0   \n",
              "2                           0                         0                   0   \n",
              "3                           1                         0                   0   \n",
              "4                           0                         1                   0   \n",
              "...                       ...                       ...                 ...   \n",
              "34294                       0                         0                   0   \n",
              "34295                       0                         0                   0   \n",
              "34296                       0                         0                   0   \n",
              "34297                       0                         0                   0   \n",
              "34298                       0                         0                   0   \n",
              "\n",
              "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
              "0                     0                       0                0   \n",
              "1                     0                       0                0   \n",
              "2                     0                       0                0   \n",
              "3                     0                       0                0   \n",
              "4                     0                       0                0   \n",
              "...                 ...                     ...              ...   \n",
              "34294                 0                       0                0   \n",
              "34295                 0                       0                0   \n",
              "34296                 0                       0                0   \n",
              "34297                 0                       0                0   \n",
              "34298                 1                       0                0   \n",
              "\n",
              "       INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
              "0                      0                         1                         0  \n",
              "1                      0                         1                         0  \n",
              "2                      0                         1                         0  \n",
              "3                      0                         1                         0  \n",
              "4                      0                         1                         0  \n",
              "...                  ...                       ...                       ...  \n",
              "34294                  0                         1                         0  \n",
              "34295                  0                         1                         0  \n",
              "34296                  0                         1                         0  \n",
              "34297                  0                         1                         0  \n",
              "34298                  0                         1                         0  \n",
              "\n",
              "[34299 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c39877f1-fc3f-4948-aeee-ef1a0a1a2b21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>NAME_ALPHA PHI SIGMA</th>\n",
              "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
              "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
              "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
              "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
              "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
              "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
              "      <th>...</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>996009318</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>996010315</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>996012607</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>996015768</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>996086871</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows × 96 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c39877f1-fc3f-4948-aeee-ef1a0a1a2b21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c39877f1-fc3f-4948-aeee-ef1a0a1a2b21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c39877f1-fc3f-4948-aeee-ef1a0a1a2b21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splits  preprocessed data into our features and target arrays\n",
        "y = dummies_df['IS_SUCCESSFUL'].values\n",
        "X = dummies_df.drop(columns=[\"IS_SUCCESSFUL\"]).values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n"
      ],
      "metadata": {
        "id": "un3HhB6qVpvz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "6F0MkbJQxlbF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test_scaled[0])"
      ],
      "metadata": {
        "id": "SE4B3Ac2tWwS",
        "outputId": "e884f9ca-3cb8-4edd-b84d-44b583ae1fc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIMIZATION ATTEMPT 1: 'ALTERED BINS, ADDED NEURONS, ADDED EPOCHS'\n",
        "# using the neuron rule of thumb, but making it two times the amount of features after numericizing the categorical data (190 neurons).\n",
        "\n",
        "# Defines the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer_1= 2*number_input_features\n",
        "hidden_nodes_layer_2 = 2*number_input_features\n",
        "hidden_nodes_layer_3 = 2*number_input_features\n",
        "\n",
        "nn1 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn1.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer_1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer_2, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "nn1.summary()"
      ],
      "metadata": {
        "id": "M7MaAFe9zcMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af9693c0-12e7-43c7-8c74-2ddb97a2a43d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 190)               18240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 190)               36290     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 191       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,721\n",
            "Trainable params: 54,721\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "nn1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "GXtZHFivdGMD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = nn1.fit(X_train_scaled,y_train,epochs=150, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESmibfmAdLTj",
        "outputId": "dc286bbb-7c5e-4282-b107-db8b913ef77c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "804/804 [==============================] - 4s 3ms/step - loss: 0.5124 - accuracy: 0.7457 - val_loss: 0.5003 - val_accuracy: 0.7503\n",
            "Epoch 2/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4918 - accuracy: 0.7580 - val_loss: 0.4966 - val_accuracy: 0.7506\n",
            "Epoch 3/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4868 - accuracy: 0.7593 - val_loss: 0.4968 - val_accuracy: 0.7514\n",
            "Epoch 4/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4852 - accuracy: 0.7602 - val_loss: 0.4955 - val_accuracy: 0.7518\n",
            "Epoch 5/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4833 - accuracy: 0.7627 - val_loss: 0.4961 - val_accuracy: 0.7522\n",
            "Epoch 6/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4811 - accuracy: 0.7626 - val_loss: 0.4923 - val_accuracy: 0.7541\n",
            "Epoch 7/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4804 - accuracy: 0.7659 - val_loss: 0.4993 - val_accuracy: 0.7502\n",
            "Epoch 8/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4793 - accuracy: 0.7647 - val_loss: 0.4941 - val_accuracy: 0.7536\n",
            "Epoch 9/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4779 - accuracy: 0.7662 - val_loss: 0.4944 - val_accuracy: 0.7522\n",
            "Epoch 10/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4767 - accuracy: 0.7662 - val_loss: 0.4939 - val_accuracy: 0.7508\n",
            "Epoch 11/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7683 - val_loss: 0.4955 - val_accuracy: 0.7495\n",
            "Epoch 12/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4754 - accuracy: 0.7673 - val_loss: 0.4930 - val_accuracy: 0.7499\n",
            "Epoch 13/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4742 - accuracy: 0.7684 - val_loss: 0.4927 - val_accuracy: 0.7542\n",
            "Epoch 14/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4735 - accuracy: 0.7683 - val_loss: 0.4959 - val_accuracy: 0.7550\n",
            "Epoch 15/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4739 - accuracy: 0.7682 - val_loss: 0.4916 - val_accuracy: 0.7537\n",
            "Epoch 16/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4717 - accuracy: 0.7690 - val_loss: 0.4973 - val_accuracy: 0.7510\n",
            "Epoch 17/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4714 - accuracy: 0.7696 - val_loss: 0.4937 - val_accuracy: 0.7556\n",
            "Epoch 18/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4704 - accuracy: 0.7694 - val_loss: 0.4944 - val_accuracy: 0.7570\n",
            "Epoch 19/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4693 - accuracy: 0.7716 - val_loss: 0.4938 - val_accuracy: 0.7541\n",
            "Epoch 20/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4690 - accuracy: 0.7712 - val_loss: 0.4963 - val_accuracy: 0.7538\n",
            "Epoch 21/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4676 - accuracy: 0.7724 - val_loss: 0.5015 - val_accuracy: 0.7532\n",
            "Epoch 22/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4681 - accuracy: 0.7730 - val_loss: 0.4926 - val_accuracy: 0.7556\n",
            "Epoch 23/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4667 - accuracy: 0.7731 - val_loss: 0.4957 - val_accuracy: 0.7552\n",
            "Epoch 24/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4657 - accuracy: 0.7744 - val_loss: 0.4995 - val_accuracy: 0.7551\n",
            "Epoch 25/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4656 - accuracy: 0.7731 - val_loss: 0.4971 - val_accuracy: 0.7564\n",
            "Epoch 26/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4646 - accuracy: 0.7741 - val_loss: 0.4929 - val_accuracy: 0.7557\n",
            "Epoch 27/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4637 - accuracy: 0.7732 - val_loss: 0.4975 - val_accuracy: 0.7518\n",
            "Epoch 28/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4631 - accuracy: 0.7758 - val_loss: 0.5001 - val_accuracy: 0.7556\n",
            "Epoch 29/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4631 - accuracy: 0.7746 - val_loss: 0.5069 - val_accuracy: 0.7564\n",
            "Epoch 30/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4633 - accuracy: 0.7752 - val_loss: 0.5050 - val_accuracy: 0.7543\n",
            "Epoch 31/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4628 - accuracy: 0.7762 - val_loss: 0.5008 - val_accuracy: 0.7565\n",
            "Epoch 32/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4604 - accuracy: 0.7769 - val_loss: 0.5014 - val_accuracy: 0.7562\n",
            "Epoch 33/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4603 - accuracy: 0.7768 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 34/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4597 - accuracy: 0.7770 - val_loss: 0.5054 - val_accuracy: 0.7583\n",
            "Epoch 35/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.7779 - val_loss: 0.5014 - val_accuracy: 0.7553\n",
            "Epoch 36/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4583 - accuracy: 0.7786 - val_loss: 0.5066 - val_accuracy: 0.7565\n",
            "Epoch 37/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4589 - accuracy: 0.7778 - val_loss: 0.5013 - val_accuracy: 0.7571\n",
            "Epoch 38/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4573 - accuracy: 0.7788 - val_loss: 0.5072 - val_accuracy: 0.7545\n",
            "Epoch 39/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4569 - accuracy: 0.7783 - val_loss: 0.5059 - val_accuracy: 0.7562\n",
            "Epoch 40/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4566 - accuracy: 0.7787 - val_loss: 0.5118 - val_accuracy: 0.7553\n",
            "Epoch 41/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4581 - accuracy: 0.7797 - val_loss: 0.5057 - val_accuracy: 0.7574\n",
            "Epoch 42/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.7792 - val_loss: 0.5044 - val_accuracy: 0.7580\n",
            "Epoch 43/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4548 - accuracy: 0.7799 - val_loss: 0.5109 - val_accuracy: 0.7560\n",
            "Epoch 44/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.7795 - val_loss: 0.5057 - val_accuracy: 0.7579\n",
            "Epoch 45/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4542 - accuracy: 0.7811 - val_loss: 0.5099 - val_accuracy: 0.7578\n",
            "Epoch 46/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4537 - accuracy: 0.7807 - val_loss: 0.5121 - val_accuracy: 0.7579\n",
            "Epoch 47/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4538 - accuracy: 0.7799 - val_loss: 0.5164 - val_accuracy: 0.7567\n",
            "Epoch 48/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4537 - accuracy: 0.7805 - val_loss: 0.5169 - val_accuracy: 0.7567\n",
            "Epoch 49/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4524 - accuracy: 0.7809 - val_loss: 0.5136 - val_accuracy: 0.7584\n",
            "Epoch 50/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4523 - accuracy: 0.7811 - val_loss: 0.5172 - val_accuracy: 0.7613\n",
            "Epoch 51/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7804 - val_loss: 0.5134 - val_accuracy: 0.7564\n",
            "Epoch 52/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4514 - accuracy: 0.7811 - val_loss: 0.5146 - val_accuracy: 0.7579\n",
            "Epoch 53/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4511 - accuracy: 0.7819 - val_loss: 0.5237 - val_accuracy: 0.7597\n",
            "Epoch 54/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4506 - accuracy: 0.7812 - val_loss: 0.5204 - val_accuracy: 0.7572\n",
            "Epoch 55/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.7817 - val_loss: 0.5151 - val_accuracy: 0.7563\n",
            "Epoch 56/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4497 - accuracy: 0.7826 - val_loss: 0.5156 - val_accuracy: 0.7563\n",
            "Epoch 57/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4513 - accuracy: 0.7822 - val_loss: 0.5191 - val_accuracy: 0.7565\n",
            "Epoch 58/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4497 - accuracy: 0.7828 - val_loss: 0.5191 - val_accuracy: 0.7545\n",
            "Epoch 59/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4499 - accuracy: 0.7820 - val_loss: 0.5223 - val_accuracy: 0.7576\n",
            "Epoch 60/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4493 - accuracy: 0.7816 - val_loss: 0.5224 - val_accuracy: 0.7580\n",
            "Epoch 61/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4487 - accuracy: 0.7821 - val_loss: 0.5143 - val_accuracy: 0.7572\n",
            "Epoch 62/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4485 - accuracy: 0.7818 - val_loss: 0.5233 - val_accuracy: 0.7541\n",
            "Epoch 63/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4481 - accuracy: 0.7823 - val_loss: 0.5250 - val_accuracy: 0.7545\n",
            "Epoch 64/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4480 - accuracy: 0.7831 - val_loss: 0.5234 - val_accuracy: 0.7600\n",
            "Epoch 65/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4490 - accuracy: 0.7825 - val_loss: 0.5247 - val_accuracy: 0.7576\n",
            "Epoch 66/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4474 - accuracy: 0.7847 - val_loss: 0.5215 - val_accuracy: 0.7566\n",
            "Epoch 67/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4473 - accuracy: 0.7832 - val_loss: 0.5253 - val_accuracy: 0.7606\n",
            "Epoch 68/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4475 - accuracy: 0.7841 - val_loss: 0.5276 - val_accuracy: 0.7537\n",
            "Epoch 69/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4468 - accuracy: 0.7835 - val_loss: 0.5234 - val_accuracy: 0.7579\n",
            "Epoch 70/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4465 - accuracy: 0.7841 - val_loss: 0.5300 - val_accuracy: 0.7595\n",
            "Epoch 71/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4459 - accuracy: 0.7837 - val_loss: 0.5267 - val_accuracy: 0.7586\n",
            "Epoch 72/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4457 - accuracy: 0.7844 - val_loss: 0.5303 - val_accuracy: 0.7577\n",
            "Epoch 73/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4456 - accuracy: 0.7829 - val_loss: 0.5267 - val_accuracy: 0.7574\n",
            "Epoch 74/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4451 - accuracy: 0.7842 - val_loss: 0.5362 - val_accuracy: 0.7569\n",
            "Epoch 75/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4452 - accuracy: 0.7843 - val_loss: 0.5304 - val_accuracy: 0.7567\n",
            "Epoch 76/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4458 - accuracy: 0.7839 - val_loss: 0.5301 - val_accuracy: 0.7574\n",
            "Epoch 77/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4444 - accuracy: 0.7835 - val_loss: 0.5322 - val_accuracy: 0.7581\n",
            "Epoch 78/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.7839 - val_loss: 0.5347 - val_accuracy: 0.7549\n",
            "Epoch 79/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4439 - accuracy: 0.7838 - val_loss: 0.5340 - val_accuracy: 0.7581\n",
            "Epoch 80/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4435 - accuracy: 0.7848 - val_loss: 0.5445 - val_accuracy: 0.7537\n",
            "Epoch 81/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4437 - accuracy: 0.7835 - val_loss: 0.5385 - val_accuracy: 0.7586\n",
            "Epoch 82/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4438 - accuracy: 0.7847 - val_loss: 0.5376 - val_accuracy: 0.7551\n",
            "Epoch 83/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4434 - accuracy: 0.7836 - val_loss: 0.5459 - val_accuracy: 0.7560\n",
            "Epoch 84/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4438 - accuracy: 0.7853 - val_loss: 0.5410 - val_accuracy: 0.7583\n",
            "Epoch 85/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4431 - accuracy: 0.7841 - val_loss: 0.5393 - val_accuracy: 0.7579\n",
            "Epoch 86/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4436 - accuracy: 0.7835 - val_loss: 0.5308 - val_accuracy: 0.7580\n",
            "Epoch 87/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4425 - accuracy: 0.7845 - val_loss: 0.5405 - val_accuracy: 0.7552\n",
            "Epoch 88/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4430 - accuracy: 0.7851 - val_loss: 0.5418 - val_accuracy: 0.7586\n",
            "Epoch 89/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4421 - accuracy: 0.7858 - val_loss: 0.5406 - val_accuracy: 0.7569\n",
            "Epoch 90/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4418 - accuracy: 0.7861 - val_loss: 0.5371 - val_accuracy: 0.7574\n",
            "Epoch 91/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4416 - accuracy: 0.7857 - val_loss: 0.5433 - val_accuracy: 0.7577\n",
            "Epoch 92/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4413 - accuracy: 0.7857 - val_loss: 0.5414 - val_accuracy: 0.7586\n",
            "Epoch 93/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4409 - accuracy: 0.7855 - val_loss: 0.5472 - val_accuracy: 0.7577\n",
            "Epoch 94/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4408 - accuracy: 0.7851 - val_loss: 0.5442 - val_accuracy: 0.7598\n",
            "Epoch 95/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4437 - accuracy: 0.7858 - val_loss: 0.5397 - val_accuracy: 0.7607\n",
            "Epoch 96/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4415 - accuracy: 0.7855 - val_loss: 0.5401 - val_accuracy: 0.7586\n",
            "Epoch 97/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4412 - accuracy: 0.7850 - val_loss: 0.5447 - val_accuracy: 0.7593\n",
            "Epoch 98/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4402 - accuracy: 0.7866 - val_loss: 0.5528 - val_accuracy: 0.7577\n",
            "Epoch 99/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4411 - accuracy: 0.7848 - val_loss: 0.5444 - val_accuracy: 0.7574\n",
            "Epoch 100/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4388 - accuracy: 0.7856 - val_loss: 0.5541 - val_accuracy: 0.7577\n",
            "Epoch 101/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4394 - accuracy: 0.7869 - val_loss: 0.5491 - val_accuracy: 0.7595\n",
            "Epoch 102/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4399 - accuracy: 0.7856 - val_loss: 0.5492 - val_accuracy: 0.7576\n",
            "Epoch 103/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4396 - accuracy: 0.7863 - val_loss: 0.5485 - val_accuracy: 0.7556\n",
            "Epoch 104/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4393 - accuracy: 0.7859 - val_loss: 0.5591 - val_accuracy: 0.7577\n",
            "Epoch 105/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4395 - accuracy: 0.7856 - val_loss: 0.5545 - val_accuracy: 0.7559\n",
            "Epoch 106/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4391 - accuracy: 0.7856 - val_loss: 0.5582 - val_accuracy: 0.7572\n",
            "Epoch 107/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4392 - accuracy: 0.7855 - val_loss: 0.5576 - val_accuracy: 0.7549\n",
            "Epoch 108/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4399 - accuracy: 0.7872 - val_loss: 0.5566 - val_accuracy: 0.7573\n",
            "Epoch 109/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4380 - accuracy: 0.7878 - val_loss: 0.5607 - val_accuracy: 0.7572\n",
            "Epoch 110/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4377 - accuracy: 0.7875 - val_loss: 0.5662 - val_accuracy: 0.7576\n",
            "Epoch 111/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4385 - accuracy: 0.7858 - val_loss: 0.5582 - val_accuracy: 0.7594\n",
            "Epoch 112/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4377 - accuracy: 0.7861 - val_loss: 0.5716 - val_accuracy: 0.7548\n",
            "Epoch 113/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4382 - accuracy: 0.7866 - val_loss: 0.5640 - val_accuracy: 0.7576\n",
            "Epoch 114/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4380 - accuracy: 0.7867 - val_loss: 0.5740 - val_accuracy: 0.7572\n",
            "Epoch 115/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4414 - accuracy: 0.7876 - val_loss: 0.5647 - val_accuracy: 0.7580\n",
            "Epoch 116/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4383 - accuracy: 0.7860 - val_loss: 0.5681 - val_accuracy: 0.7593\n",
            "Epoch 117/150\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4371 - accuracy: 0.7868 - val_loss: 0.5728 - val_accuracy: 0.7594\n",
            "Epoch 118/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4372 - accuracy: 0.7864 - val_loss: 0.5709 - val_accuracy: 0.7583\n",
            "Epoch 119/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4371 - accuracy: 0.7872 - val_loss: 0.5821 - val_accuracy: 0.7580\n",
            "Epoch 120/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4363 - accuracy: 0.7866 - val_loss: 0.5758 - val_accuracy: 0.7571\n",
            "Epoch 121/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4371 - accuracy: 0.7872 - val_loss: 0.5797 - val_accuracy: 0.7588\n",
            "Epoch 122/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4370 - accuracy: 0.7861 - val_loss: 0.5897 - val_accuracy: 0.7576\n",
            "Epoch 123/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4370 - accuracy: 0.7874 - val_loss: 0.5831 - val_accuracy: 0.7569\n",
            "Epoch 124/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4373 - accuracy: 0.7876 - val_loss: 0.5774 - val_accuracy: 0.7583\n",
            "Epoch 125/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4354 - accuracy: 0.7868 - val_loss: 0.5833 - val_accuracy: 0.7570\n",
            "Epoch 126/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.7888 - val_loss: 0.5799 - val_accuracy: 0.7565\n",
            "Epoch 127/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4359 - accuracy: 0.7871 - val_loss: 0.5859 - val_accuracy: 0.7588\n",
            "Epoch 128/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.7872 - val_loss: 0.5922 - val_accuracy: 0.7552\n",
            "Epoch 129/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4364 - accuracy: 0.7872 - val_loss: 0.5905 - val_accuracy: 0.7573\n",
            "Epoch 130/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4351 - accuracy: 0.7870 - val_loss: 0.5952 - val_accuracy: 0.7584\n",
            "Epoch 131/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4421 - accuracy: 0.7877 - val_loss: 0.6148 - val_accuracy: 0.7569\n",
            "Epoch 132/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4429 - accuracy: 0.7873 - val_loss: 0.6048 - val_accuracy: 0.7585\n",
            "Epoch 133/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4347 - accuracy: 0.7888 - val_loss: 0.6001 - val_accuracy: 0.7591\n",
            "Epoch 134/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4332 - accuracy: 0.7896 - val_loss: 0.6162 - val_accuracy: 0.7556\n",
            "Epoch 135/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.7872 - val_loss: 0.5994 - val_accuracy: 0.7558\n",
            "Epoch 136/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4337 - accuracy: 0.7891 - val_loss: 0.6002 - val_accuracy: 0.7551\n",
            "Epoch 137/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4336 - accuracy: 0.7886 - val_loss: 0.5991 - val_accuracy: 0.7573\n",
            "Epoch 138/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4335 - accuracy: 0.7884 - val_loss: 0.6108 - val_accuracy: 0.7570\n",
            "Epoch 139/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4344 - accuracy: 0.7879 - val_loss: 0.6021 - val_accuracy: 0.7587\n",
            "Epoch 140/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4331 - accuracy: 0.7886 - val_loss: 0.6110 - val_accuracy: 0.7579\n",
            "Epoch 141/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4346 - accuracy: 0.7867 - val_loss: 0.6009 - val_accuracy: 0.7567\n",
            "Epoch 142/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4339 - accuracy: 0.7887 - val_loss: 0.6037 - val_accuracy: 0.7586\n",
            "Epoch 143/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4340 - accuracy: 0.7892 - val_loss: 0.6010 - val_accuracy: 0.7591\n",
            "Epoch 144/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4340 - accuracy: 0.7887 - val_loss: 0.5971 - val_accuracy: 0.7559\n",
            "Epoch 145/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4338 - accuracy: 0.7895 - val_loss: 0.6029 - val_accuracy: 0.7577\n",
            "Epoch 146/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4338 - accuracy: 0.7883 - val_loss: 0.6037 - val_accuracy: 0.7558\n",
            "Epoch 147/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.7890 - val_loss: 0.5929 - val_accuracy: 0.7560\n",
            "Epoch 148/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4333 - accuracy: 0.7883 - val_loss: 0.5983 - val_accuracy: 0.7525\n",
            "Epoch 149/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4323 - accuracy: 0.7892 - val_loss: 0.5988 - val_accuracy: 0.7569\n",
            "Epoch 150/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4328 - accuracy: 0.7884 - val_loss: 0.6075 - val_accuracy: 0.7560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluates Optimization model 1 using the test data\n",
        "#Optimization model meets the >75% threshold.\n",
        "model_loss, model_accuracy = nn1.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcmBS0oUjFhi",
        "outputId": "ab40f132-7cdf-45ed-e358-681f204770b5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 - 0s - loss: 0.6075 - accuracy: 0.7560 - 334ms/epoch - 1ms/step\n",
            "Loss: 0.6074892282485962, Accuracy: 0.7560349702835083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves Optimization model 1 to HDF5\n",
        "nn1.save('AlphabetSoupCharity_Optimisation1.h5')"
      ],
      "metadata": {
        "id": "qW-t_ll-joD-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIMIZATION ATTEMPT #2 REVISED BINS, ADDED LAYER, STEPPED NEURONS, ADDED EPOCHS\n",
        "## Adding fourth layer (1 input, 2 hidden, 1 output) consisting of the same amount of neurons.\n",
        "##Neurons are stepped up in size.\n",
        "\n",
        "\n",
        "hidden_nodes_layer_1= number_input_features\n",
        "hidden_nodes_layer_2 = 2*number_input_features\n",
        "hidden_nodes_layer_3 = 3*number_input_features\n",
        "nn2 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn2.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer_1, input_dim=number_input_features, activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer_2, activation=\"relu\"))\n",
        "\n",
        "\n",
        "# Third hidden layer\n",
        "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer_3, activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "nn2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tffnrcfjKMp",
        "outputId": "e3676061-ca96-4422-fbe9-70d734b942c6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 95)                9120      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 190)               18240     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 285)               54435     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 286       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,081\n",
            "Trainable params: 82,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiles the model\n",
        "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yluj6Hk6l0Dv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = nn2.fit(X_train_scaled,y_train,epochs=150, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN4xbeXal99b",
        "outputId": "ca3f9a9e-28a9-400c-d750-c99757f345a2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5125 - accuracy: 0.7465 - val_loss: 0.5015 - val_accuracy: 0.7486\n",
            "Epoch 2/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4909 - accuracy: 0.7594 - val_loss: 0.4974 - val_accuracy: 0.7510\n",
            "Epoch 3/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4872 - accuracy: 0.7618 - val_loss: 0.4945 - val_accuracy: 0.7522\n",
            "Epoch 4/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4841 - accuracy: 0.7627 - val_loss: 0.4927 - val_accuracy: 0.7515\n",
            "Epoch 5/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4825 - accuracy: 0.7640 - val_loss: 0.4966 - val_accuracy: 0.7462\n",
            "Epoch 6/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4815 - accuracy: 0.7640 - val_loss: 0.4971 - val_accuracy: 0.7514\n",
            "Epoch 7/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4800 - accuracy: 0.7642 - val_loss: 0.4943 - val_accuracy: 0.7546\n",
            "Epoch 8/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4781 - accuracy: 0.7660 - val_loss: 0.4930 - val_accuracy: 0.7499\n",
            "Epoch 9/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4777 - accuracy: 0.7669 - val_loss: 0.4960 - val_accuracy: 0.7488\n",
            "Epoch 10/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4760 - accuracy: 0.7685 - val_loss: 0.4916 - val_accuracy: 0.7532\n",
            "Epoch 11/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4753 - accuracy: 0.7696 - val_loss: 0.4932 - val_accuracy: 0.7543\n",
            "Epoch 12/150\n",
            "804/804 [==============================] - 4s 5ms/step - loss: 0.4748 - accuracy: 0.7689 - val_loss: 0.4928 - val_accuracy: 0.7537\n",
            "Epoch 13/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4732 - accuracy: 0.7707 - val_loss: 0.4961 - val_accuracy: 0.7536\n",
            "Epoch 14/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4721 - accuracy: 0.7699 - val_loss: 0.4919 - val_accuracy: 0.7543\n",
            "Epoch 15/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4713 - accuracy: 0.7715 - val_loss: 0.4940 - val_accuracy: 0.7550\n",
            "Epoch 16/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4701 - accuracy: 0.7719 - val_loss: 0.4937 - val_accuracy: 0.7549\n",
            "Epoch 17/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4701 - accuracy: 0.7724 - val_loss: 0.4979 - val_accuracy: 0.7565\n",
            "Epoch 18/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4689 - accuracy: 0.7730 - val_loss: 0.4972 - val_accuracy: 0.7558\n",
            "Epoch 19/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4673 - accuracy: 0.7732 - val_loss: 0.4989 - val_accuracy: 0.7564\n",
            "Epoch 20/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4662 - accuracy: 0.7736 - val_loss: 0.5008 - val_accuracy: 0.7539\n",
            "Epoch 21/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4657 - accuracy: 0.7737 - val_loss: 0.4955 - val_accuracy: 0.7548\n",
            "Epoch 22/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4647 - accuracy: 0.7754 - val_loss: 0.4978 - val_accuracy: 0.7553\n",
            "Epoch 23/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4642 - accuracy: 0.7750 - val_loss: 0.4993 - val_accuracy: 0.7574\n",
            "Epoch 24/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4626 - accuracy: 0.7754 - val_loss: 0.4989 - val_accuracy: 0.7552\n",
            "Epoch 25/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4626 - accuracy: 0.7750 - val_loss: 0.5011 - val_accuracy: 0.7552\n",
            "Epoch 26/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4617 - accuracy: 0.7769 - val_loss: 0.5012 - val_accuracy: 0.7542\n",
            "Epoch 27/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4613 - accuracy: 0.7769 - val_loss: 0.5092 - val_accuracy: 0.7522\n",
            "Epoch 28/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.5027 - val_accuracy: 0.7552\n",
            "Epoch 29/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4592 - accuracy: 0.7775 - val_loss: 0.5040 - val_accuracy: 0.7560\n",
            "Epoch 30/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4584 - accuracy: 0.7775 - val_loss: 0.5068 - val_accuracy: 0.7569\n",
            "Epoch 31/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4576 - accuracy: 0.7773 - val_loss: 0.5144 - val_accuracy: 0.7557\n",
            "Epoch 32/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4568 - accuracy: 0.7786 - val_loss: 0.5136 - val_accuracy: 0.7562\n",
            "Epoch 33/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4560 - accuracy: 0.7799 - val_loss: 0.5122 - val_accuracy: 0.7560\n",
            "Epoch 34/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4552 - accuracy: 0.7792 - val_loss: 0.5184 - val_accuracy: 0.7574\n",
            "Epoch 35/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4538 - accuracy: 0.7809 - val_loss: 0.5157 - val_accuracy: 0.7551\n",
            "Epoch 36/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4549 - accuracy: 0.7797 - val_loss: 0.5150 - val_accuracy: 0.7577\n",
            "Epoch 37/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4529 - accuracy: 0.7794 - val_loss: 0.5204 - val_accuracy: 0.7574\n",
            "Epoch 38/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4524 - accuracy: 0.7816 - val_loss: 0.5151 - val_accuracy: 0.7573\n",
            "Epoch 39/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4520 - accuracy: 0.7818 - val_loss: 0.5302 - val_accuracy: 0.7557\n",
            "Epoch 40/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4525 - accuracy: 0.7800 - val_loss: 0.5159 - val_accuracy: 0.7579\n",
            "Epoch 41/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4509 - accuracy: 0.7812 - val_loss: 0.5223 - val_accuracy: 0.7579\n",
            "Epoch 42/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4508 - accuracy: 0.7814 - val_loss: 0.5238 - val_accuracy: 0.7590\n",
            "Epoch 43/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4505 - accuracy: 0.7816 - val_loss: 0.5199 - val_accuracy: 0.7593\n",
            "Epoch 44/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4497 - accuracy: 0.7821 - val_loss: 0.5217 - val_accuracy: 0.7592\n",
            "Epoch 45/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4491 - accuracy: 0.7821 - val_loss: 0.5223 - val_accuracy: 0.7590\n",
            "Epoch 46/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4484 - accuracy: 0.7839 - val_loss: 0.5311 - val_accuracy: 0.7591\n",
            "Epoch 47/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4474 - accuracy: 0.7823 - val_loss: 0.5331 - val_accuracy: 0.7578\n",
            "Epoch 48/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4473 - accuracy: 0.7839 - val_loss: 0.5390 - val_accuracy: 0.7566\n",
            "Epoch 49/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4476 - accuracy: 0.7827 - val_loss: 0.5270 - val_accuracy: 0.7565\n",
            "Epoch 50/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4470 - accuracy: 0.7835 - val_loss: 0.5288 - val_accuracy: 0.7586\n",
            "Epoch 51/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4453 - accuracy: 0.7848 - val_loss: 0.5340 - val_accuracy: 0.7573\n",
            "Epoch 52/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4448 - accuracy: 0.7834 - val_loss: 0.5427 - val_accuracy: 0.7557\n",
            "Epoch 53/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4463 - accuracy: 0.7839 - val_loss: 0.5501 - val_accuracy: 0.7553\n",
            "Epoch 54/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4457 - accuracy: 0.7837 - val_loss: 0.5283 - val_accuracy: 0.7571\n",
            "Epoch 55/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4442 - accuracy: 0.7839 - val_loss: 0.5349 - val_accuracy: 0.7563\n",
            "Epoch 56/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4433 - accuracy: 0.7849 - val_loss: 0.5528 - val_accuracy: 0.7559\n",
            "Epoch 57/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4429 - accuracy: 0.7844 - val_loss: 0.5503 - val_accuracy: 0.7574\n",
            "Epoch 58/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4422 - accuracy: 0.7851 - val_loss: 0.5646 - val_accuracy: 0.7569\n",
            "Epoch 59/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4429 - accuracy: 0.7854 - val_loss: 0.5476 - val_accuracy: 0.7571\n",
            "Epoch 60/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4422 - accuracy: 0.7863 - val_loss: 0.5602 - val_accuracy: 0.7578\n",
            "Epoch 61/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4416 - accuracy: 0.7858 - val_loss: 0.5692 - val_accuracy: 0.7562\n",
            "Epoch 62/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4429 - accuracy: 0.7848 - val_loss: 0.5539 - val_accuracy: 0.7566\n",
            "Epoch 63/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4413 - accuracy: 0.7858 - val_loss: 0.5646 - val_accuracy: 0.7551\n",
            "Epoch 64/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4412 - accuracy: 0.7854 - val_loss: 0.5711 - val_accuracy: 0.7536\n",
            "Epoch 65/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4405 - accuracy: 0.7851 - val_loss: 0.5723 - val_accuracy: 0.7570\n",
            "Epoch 66/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4410 - accuracy: 0.7871 - val_loss: 0.5849 - val_accuracy: 0.7538\n",
            "Epoch 67/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4441 - accuracy: 0.7863 - val_loss: 0.5674 - val_accuracy: 0.7556\n",
            "Epoch 68/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4395 - accuracy: 0.7871 - val_loss: 0.5799 - val_accuracy: 0.7545\n",
            "Epoch 69/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4396 - accuracy: 0.7871 - val_loss: 0.5721 - val_accuracy: 0.7542\n",
            "Epoch 70/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4400 - accuracy: 0.7874 - val_loss: 0.5900 - val_accuracy: 0.7557\n",
            "Epoch 71/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4390 - accuracy: 0.7872 - val_loss: 0.5719 - val_accuracy: 0.7545\n",
            "Epoch 72/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4376 - accuracy: 0.7864 - val_loss: 0.5744 - val_accuracy: 0.7566\n",
            "Epoch 73/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4382 - accuracy: 0.7872 - val_loss: 0.5723 - val_accuracy: 0.7541\n",
            "Epoch 74/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4377 - accuracy: 0.7866 - val_loss: 0.5934 - val_accuracy: 0.7569\n",
            "Epoch 75/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4379 - accuracy: 0.7876 - val_loss: 0.5856 - val_accuracy: 0.7529\n",
            "Epoch 76/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4382 - accuracy: 0.7866 - val_loss: 0.5895 - val_accuracy: 0.7576\n",
            "Epoch 77/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4376 - accuracy: 0.7879 - val_loss: 0.5785 - val_accuracy: 0.7559\n",
            "Epoch 78/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4378 - accuracy: 0.7883 - val_loss: 0.5858 - val_accuracy: 0.7565\n",
            "Epoch 79/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4367 - accuracy: 0.7883 - val_loss: 0.5927 - val_accuracy: 0.7573\n",
            "Epoch 80/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4365 - accuracy: 0.7887 - val_loss: 0.5942 - val_accuracy: 0.7551\n",
            "Epoch 81/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4356 - accuracy: 0.7886 - val_loss: 0.6271 - val_accuracy: 0.7545\n",
            "Epoch 82/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4366 - accuracy: 0.7882 - val_loss: 0.6067 - val_accuracy: 0.7567\n",
            "Epoch 83/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4427 - accuracy: 0.7873 - val_loss: 0.6072 - val_accuracy: 0.7544\n",
            "Epoch 84/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4349 - accuracy: 0.7881 - val_loss: 0.5889 - val_accuracy: 0.7543\n",
            "Epoch 85/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4344 - accuracy: 0.7897 - val_loss: 0.6102 - val_accuracy: 0.7573\n",
            "Epoch 86/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4345 - accuracy: 0.7885 - val_loss: 0.6051 - val_accuracy: 0.7564\n",
            "Epoch 87/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.7900 - val_loss: 0.5993 - val_accuracy: 0.7550\n",
            "Epoch 88/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4347 - accuracy: 0.7892 - val_loss: 0.5900 - val_accuracy: 0.7562\n",
            "Epoch 89/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4342 - accuracy: 0.7893 - val_loss: 0.5899 - val_accuracy: 0.7548\n",
            "Epoch 90/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4336 - accuracy: 0.7892 - val_loss: 0.6053 - val_accuracy: 0.7566\n",
            "Epoch 91/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4341 - accuracy: 0.7879 - val_loss: 0.6191 - val_accuracy: 0.7552\n",
            "Epoch 92/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4350 - accuracy: 0.7892 - val_loss: 0.5904 - val_accuracy: 0.7562\n",
            "Epoch 93/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4333 - accuracy: 0.7907 - val_loss: 0.6038 - val_accuracy: 0.7525\n",
            "Epoch 94/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4342 - accuracy: 0.7911 - val_loss: 0.6212 - val_accuracy: 0.7558\n",
            "Epoch 95/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4331 - accuracy: 0.7900 - val_loss: 0.6240 - val_accuracy: 0.7553\n",
            "Epoch 96/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4331 - accuracy: 0.7896 - val_loss: 0.5960 - val_accuracy: 0.7548\n",
            "Epoch 97/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4334 - accuracy: 0.7885 - val_loss: 0.6210 - val_accuracy: 0.7573\n",
            "Epoch 98/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4320 - accuracy: 0.7897 - val_loss: 0.6061 - val_accuracy: 0.7548\n",
            "Epoch 99/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4349 - accuracy: 0.7891 - val_loss: 0.6015 - val_accuracy: 0.7565\n",
            "Epoch 100/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4319 - accuracy: 0.7909 - val_loss: 0.6184 - val_accuracy: 0.7548\n",
            "Epoch 101/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4310 - accuracy: 0.7897 - val_loss: 0.6228 - val_accuracy: 0.7546\n",
            "Epoch 102/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4341 - accuracy: 0.7898 - val_loss: 0.6161 - val_accuracy: 0.7550\n",
            "Epoch 103/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4304 - accuracy: 0.7916 - val_loss: 0.6133 - val_accuracy: 0.7559\n",
            "Epoch 104/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4313 - accuracy: 0.7899 - val_loss: 0.6175 - val_accuracy: 0.7545\n",
            "Epoch 105/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4311 - accuracy: 0.7889 - val_loss: 0.6369 - val_accuracy: 0.7559\n",
            "Epoch 106/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4306 - accuracy: 0.7899 - val_loss: 0.6308 - val_accuracy: 0.7549\n",
            "Epoch 107/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4315 - accuracy: 0.7903 - val_loss: 0.6450 - val_accuracy: 0.7528\n",
            "Epoch 108/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4313 - accuracy: 0.7912 - val_loss: 0.6367 - val_accuracy: 0.7534\n",
            "Epoch 109/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4301 - accuracy: 0.7903 - val_loss: 0.6573 - val_accuracy: 0.7545\n",
            "Epoch 110/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4301 - accuracy: 0.7911 - val_loss: 0.6556 - val_accuracy: 0.7560\n",
            "Epoch 111/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4302 - accuracy: 0.7910 - val_loss: 0.6884 - val_accuracy: 0.7563\n",
            "Epoch 112/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4346 - accuracy: 0.7895 - val_loss: 0.6769 - val_accuracy: 0.7549\n",
            "Epoch 113/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4292 - accuracy: 0.7907 - val_loss: 0.6275 - val_accuracy: 0.7552\n",
            "Epoch 114/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4290 - accuracy: 0.7915 - val_loss: 0.6559 - val_accuracy: 0.7555\n",
            "Epoch 115/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4282 - accuracy: 0.7907 - val_loss: 0.6786 - val_accuracy: 0.7537\n",
            "Epoch 116/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4288 - accuracy: 0.7923 - val_loss: 0.6883 - val_accuracy: 0.7562\n",
            "Epoch 117/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4318 - accuracy: 0.7914 - val_loss: 0.6283 - val_accuracy: 0.7559\n",
            "Epoch 118/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4290 - accuracy: 0.7914 - val_loss: 0.6605 - val_accuracy: 0.7558\n",
            "Epoch 119/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4294 - accuracy: 0.7919 - val_loss: 0.6801 - val_accuracy: 0.7536\n",
            "Epoch 120/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4284 - accuracy: 0.7911 - val_loss: 0.6688 - val_accuracy: 0.7556\n",
            "Epoch 121/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4301 - accuracy: 0.7908 - val_loss: 0.6550 - val_accuracy: 0.7570\n",
            "Epoch 122/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4283 - accuracy: 0.7930 - val_loss: 0.6527 - val_accuracy: 0.7541\n",
            "Epoch 123/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4274 - accuracy: 0.7923 - val_loss: 0.6950 - val_accuracy: 0.7523\n",
            "Epoch 124/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4295 - accuracy: 0.7910 - val_loss: 0.6792 - val_accuracy: 0.7535\n",
            "Epoch 125/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4280 - accuracy: 0.7920 - val_loss: 0.6739 - val_accuracy: 0.7537\n",
            "Epoch 126/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4297 - accuracy: 0.7909 - val_loss: 0.6821 - val_accuracy: 0.7562\n",
            "Epoch 127/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4289 - accuracy: 0.7925 - val_loss: 0.7012 - val_accuracy: 0.7545\n",
            "Epoch 128/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4252 - accuracy: 0.7937 - val_loss: 0.7176 - val_accuracy: 0.7564\n",
            "Epoch 129/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4258 - accuracy: 0.7923 - val_loss: 0.6925 - val_accuracy: 0.7564\n",
            "Epoch 130/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4284 - accuracy: 0.7925 - val_loss: 0.6814 - val_accuracy: 0.7543\n",
            "Epoch 131/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4255 - accuracy: 0.7917 - val_loss: 0.6946 - val_accuracy: 0.7545\n",
            "Epoch 132/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4262 - accuracy: 0.7916 - val_loss: 0.6802 - val_accuracy: 0.7545\n",
            "Epoch 133/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4264 - accuracy: 0.7922 - val_loss: 0.7198 - val_accuracy: 0.7559\n",
            "Epoch 134/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4259 - accuracy: 0.7921 - val_loss: 0.6939 - val_accuracy: 0.7548\n",
            "Epoch 135/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4258 - accuracy: 0.7926 - val_loss: 0.7085 - val_accuracy: 0.7553\n",
            "Epoch 136/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4254 - accuracy: 0.7929 - val_loss: 0.6866 - val_accuracy: 0.7538\n",
            "Epoch 137/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4258 - accuracy: 0.7928 - val_loss: 0.7196 - val_accuracy: 0.7558\n",
            "Epoch 138/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4262 - accuracy: 0.7923 - val_loss: 0.7259 - val_accuracy: 0.7548\n",
            "Epoch 139/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4258 - accuracy: 0.7924 - val_loss: 0.7650 - val_accuracy: 0.7555\n",
            "Epoch 140/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4292 - accuracy: 0.7924 - val_loss: 0.7267 - val_accuracy: 0.7546\n",
            "Epoch 141/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4247 - accuracy: 0.7926 - val_loss: 0.7269 - val_accuracy: 0.7570\n",
            "Epoch 142/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4279 - accuracy: 0.7925 - val_loss: 0.6955 - val_accuracy: 0.7562\n",
            "Epoch 143/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4285 - accuracy: 0.7920 - val_loss: 0.6746 - val_accuracy: 0.7563\n",
            "Epoch 144/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4245 - accuracy: 0.7935 - val_loss: 0.7125 - val_accuracy: 0.7558\n",
            "Epoch 145/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4245 - accuracy: 0.7934 - val_loss: 0.6928 - val_accuracy: 0.7539\n",
            "Epoch 146/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4250 - accuracy: 0.7936 - val_loss: 0.6844 - val_accuracy: 0.7528\n",
            "Epoch 147/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4253 - accuracy: 0.7919 - val_loss: 0.7356 - val_accuracy: 0.7559\n",
            "Epoch 148/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4254 - accuracy: 0.7928 - val_loss: 0.7164 - val_accuracy: 0.7543\n",
            "Epoch 149/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4250 - accuracy: 0.7924 - val_loss: 0.7077 - val_accuracy: 0.7528\n",
            "Epoch 150/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4254 - accuracy: 0.7933 - val_loss: 0.7535 - val_accuracy: 0.7550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKwRd6USsGJg",
        "outputId": "98b561de-c856-4594-e3da-11b61f192fb4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 0s 1ms/step - loss: 0.7535 - accuracy: 0.7550\n",
            "Loss: 0.7535280585289001, Accuracy: 0.7549854516983032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn2.save('AlphabetSoupCharity_Optimisation2.h5')"
      ],
      "metadata": {
        "id": "cRGx5b5C8-6f"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OPTIMIZATION MODEL 3 (REVISED BINS, REDUCED INPUT FEATURES, MAXIMUM NEURONS, INCREASED EPOCHS)\n",
        "reduced_df=application_df.drop(columns=['CLASSIFICATION',\"SPECIAL_CONSIDERATIONS\"])\n",
        "reduced_dummy_cats = ['NAME','AFFILIATION','APPLICATION_TYPE','STATUS','USE_CASE','ORGANIZATION','INCOME_AMT']\n",
        "reduced_dummies = pd.get_dummies(reduced_df, columns = reduced_dummy_cats)\n",
        "reduced_dummies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "m0Tu8sL09EUy",
        "outputId": "c5f76481-ad97-4f71-8a4e-ab1652c058ce"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             EIN   ASK_AMT  IS_SUCCESSFUL  NAME_ALPHA PHI SIGMA  \\\n",
              "0       10520599      5000              1                     0   \n",
              "1       10531628    108590              1                     0   \n",
              "2       10547893      5000              0                     0   \n",
              "3       10553066      6692              1                     0   \n",
              "4       10556103    142590              1                     0   \n",
              "...          ...       ...            ...                   ...   \n",
              "34294  996009318      5000              0                     0   \n",
              "34295  996010315      5000              0                     0   \n",
              "34296  996012607      5000              0                     0   \n",
              "34297  996015768      5000              1                     0   \n",
              "34298  996086871  36500179              0                     0   \n",
              "\n",
              "       NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC  \\\n",
              "0                                                      0      \n",
              "1                                                      0      \n",
              "2                                                      0      \n",
              "3                                                      0      \n",
              "4                                                      0      \n",
              "...                                                  ...      \n",
              "34294                                                  0      \n",
              "34295                                                  0      \n",
              "34296                                                  0      \n",
              "34297                                                  0      \n",
              "34298                                                  0      \n",
              "\n",
              "       NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN  \\\n",
              "0                                                  0   \n",
              "1                                                  0   \n",
              "2                                                  0   \n",
              "3                                                  0   \n",
              "4                                                  0   \n",
              "...                                              ...   \n",
              "34294                                              0   \n",
              "34295                                              0   \n",
              "34296                                              0   \n",
              "34297                                              0   \n",
              "34298                                              0   \n",
              "\n",
              "       NAME_CIVITAN INTERNATIONAL  NAME_DEMOLAY INTERNATIONAL  \\\n",
              "0                               0                           0   \n",
              "1                               0                           0   \n",
              "2                               0                           0   \n",
              "3                               0                           0   \n",
              "4                               0                           0   \n",
              "...                           ...                         ...   \n",
              "34294                           0                           0   \n",
              "34295                           0                           0   \n",
              "34296                           0                           0   \n",
              "34297                           0                           0   \n",
              "34298                           0                           0   \n",
              "\n",
              "       NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA  \\\n",
              "0                                                      0           \n",
              "1                                                      0           \n",
              "2                                                      0           \n",
              "3                                                      0           \n",
              "4                                                      0           \n",
              "...                                                  ...           \n",
              "34294                                                  0           \n",
              "34295                                                  0           \n",
              "34296                                                  0           \n",
              "34297                                                  0           \n",
              "34298                                                  0           \n",
              "\n",
              "       NAME_HABITAT FOR HUMANITY INTERNATIONAL INC  ...  ORGANIZATION_Trust  \\\n",
              "0                                                0  ...                   0   \n",
              "1                                                0  ...                   0   \n",
              "2                                                0  ...                   0   \n",
              "3                                                0  ...                   1   \n",
              "4                                                0  ...                   1   \n",
              "...                                            ...  ...                 ...   \n",
              "34294                                            0  ...                   0   \n",
              "34295                                            0  ...                   0   \n",
              "34296                                            0  ...                   0   \n",
              "34297                                            0  ...                   0   \n",
              "34298                                            0  ...                   0   \n",
              "\n",
              "       INCOME_AMT_0  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
              "0                 1                  0                       0   \n",
              "1                 0                  1                       0   \n",
              "2                 1                  0                       0   \n",
              "3                 0                  0                       1   \n",
              "4                 0                  0                       0   \n",
              "...             ...                ...                     ...   \n",
              "34294             1                  0                       0   \n",
              "34295             1                  0                       0   \n",
              "34296             1                  0                       0   \n",
              "34297             1                  0                       0   \n",
              "34298             0                  0                       0   \n",
              "\n",
              "       INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  \\\n",
              "0                             0                   0                 0   \n",
              "1                             0                   0                 0   \n",
              "2                             0                   0                 0   \n",
              "3                             0                   0                 0   \n",
              "4                             1                   0                 0   \n",
              "...                         ...                 ...               ...   \n",
              "34294                         0                   0                 0   \n",
              "34295                         0                   0                 0   \n",
              "34296                         0                   0                 0   \n",
              "34297                         0                   0                 0   \n",
              "34298                         0                   0                 1   \n",
              "\n",
              "       INCOME_AMT_25000-99999  INCOME_AMT_50M+  INCOME_AMT_5M-10M  \n",
              "0                           0                0                  0  \n",
              "1                           0                0                  0  \n",
              "2                           0                0                  0  \n",
              "3                           0                0                  0  \n",
              "4                           0                0                  0  \n",
              "...                       ...              ...                ...  \n",
              "34294                       0                0                  0  \n",
              "34295                       0                0                  0  \n",
              "34296                       0                0                  0  \n",
              "34297                       0                0                  0  \n",
              "34298                       0                0                  0  \n",
              "\n",
              "[34299 rows x 73 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11a06be9-c427-41ec-b960-4e303ccce5b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>NAME_ALPHA PHI SIGMA</th>\n",
              "      <th>NAME_AMATEUR ATHLETIC UNION OF THE UNITED STATES INC</th>\n",
              "      <th>NAME_AMERICAN ASSOCIATION OF UNIVERSITY WOMEN</th>\n",
              "      <th>NAME_CIVITAN INTERNATIONAL</th>\n",
              "      <th>NAME_DEMOLAY INTERNATIONAL</th>\n",
              "      <th>NAME_FARMERS EDUCATIONAL AND COOPERATIVE UNION OF AMERICA</th>\n",
              "      <th>NAME_HABITAT FOR HUMANITY INTERNATIONAL INC</th>\n",
              "      <th>...</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_0</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34294</th>\n",
              "      <td>996009318</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34295</th>\n",
              "      <td>996010315</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34296</th>\n",
              "      <td>996012607</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34297</th>\n",
              "      <td>996015768</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34298</th>\n",
              "      <td>996086871</td>\n",
              "      <td>36500179</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34299 rows × 73 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11a06be9-c427-41ec-b960-4e303ccce5b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11a06be9-c427-41ec-b960-4e303ccce5b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11a06be9-c427-41ec-b960-4e303ccce5b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splits our preprocessed data into our features and target arrays\n",
        "y = reduced_dummies['IS_SUCCESSFUL'].values\n",
        "X = reduced_dummies.drop(columns=\"IS_SUCCESSFUL\").values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
        "\n",
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Pe5YTPYGBXr8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defines the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "number_input_features = len(X_train_scaled[0])\n",
        "hidden_nodes_layer_1= 3*number_input_features\n",
        "hidden_nodes_layer_2 = 3*number_input_features\n",
        "hidden_nodes_layer_3 = 3*number_input_features\n",
        "\n",
        "nn3 = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn3.add(\n",
        "    tf.keras.layers.Dense(units=hidden_nodes_layer_1, input_dim=number_input_features, activation=\"ReLU\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer_2, activation=\"ReLU\"))\n",
        "\n",
        "# Third hidden layer\n",
        "nn3.add(tf.keras.layers.Dense(units=hidden_nodes_layer_3, activation=\"ReLU\"))\n",
        "\n",
        "# Output layer\n",
        "nn3.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE2OMkW9EbuG",
        "outputId": "ccd61e84-be5d-4f5e-b22f-1731bc651e82"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 216)               15768     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 216)               46872     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 216)               46872     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 217       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,729\n",
            "Trainable params: 109,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiles the model\n",
        "nn3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZazBrgFdE3Ir"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model = nn3.fit(X_train_scaled,y_train,epochs=150, validation_data=(X_test_scaled, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZJnw4_4FEys",
        "outputId": "c3885a6f-6ead-4246-bfe4-2f94ad4f7089"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.5189 - accuracy: 0.7365 - val_loss: 0.5098 - val_accuracy: 0.7343\n",
            "Epoch 2/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5041 - accuracy: 0.7437 - val_loss: 0.5064 - val_accuracy: 0.7397\n",
            "Epoch 3/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5010 - accuracy: 0.7467 - val_loss: 0.5084 - val_accuracy: 0.7405\n",
            "Epoch 4/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4998 - accuracy: 0.7455 - val_loss: 0.5064 - val_accuracy: 0.7399\n",
            "Epoch 5/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4988 - accuracy: 0.7475 - val_loss: 0.5077 - val_accuracy: 0.7398\n",
            "Epoch 6/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4980 - accuracy: 0.7472 - val_loss: 0.5102 - val_accuracy: 0.7381\n",
            "Epoch 7/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4973 - accuracy: 0.7482 - val_loss: 0.5083 - val_accuracy: 0.7376\n",
            "Epoch 8/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4961 - accuracy: 0.7483 - val_loss: 0.5057 - val_accuracy: 0.7371\n",
            "Epoch 9/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4957 - accuracy: 0.7500 - val_loss: 0.5061 - val_accuracy: 0.7409\n",
            "Epoch 10/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4946 - accuracy: 0.7498 - val_loss: 0.5068 - val_accuracy: 0.7416\n",
            "Epoch 11/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4941 - accuracy: 0.7507 - val_loss: 0.5095 - val_accuracy: 0.7392\n",
            "Epoch 12/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4939 - accuracy: 0.7509 - val_loss: 0.5079 - val_accuracy: 0.7377\n",
            "Epoch 13/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4928 - accuracy: 0.7529 - val_loss: 0.5077 - val_accuracy: 0.7402\n",
            "Epoch 14/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4929 - accuracy: 0.7526 - val_loss: 0.5073 - val_accuracy: 0.7389\n",
            "Epoch 15/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4917 - accuracy: 0.7527 - val_loss: 0.5089 - val_accuracy: 0.7409\n",
            "Epoch 16/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4911 - accuracy: 0.7539 - val_loss: 0.5061 - val_accuracy: 0.7425\n",
            "Epoch 17/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4901 - accuracy: 0.7545 - val_loss: 0.5095 - val_accuracy: 0.7433\n",
            "Epoch 18/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4905 - accuracy: 0.7539 - val_loss: 0.5100 - val_accuracy: 0.7412\n",
            "Epoch 19/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4899 - accuracy: 0.7543 - val_loss: 0.5074 - val_accuracy: 0.7433\n",
            "Epoch 20/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4890 - accuracy: 0.7548 - val_loss: 0.5139 - val_accuracy: 0.7415\n",
            "Epoch 21/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4890 - accuracy: 0.7549 - val_loss: 0.5075 - val_accuracy: 0.7447\n",
            "Epoch 22/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4876 - accuracy: 0.7548 - val_loss: 0.5115 - val_accuracy: 0.7427\n",
            "Epoch 23/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4880 - accuracy: 0.7552 - val_loss: 0.5122 - val_accuracy: 0.7450\n",
            "Epoch 24/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4876 - accuracy: 0.7561 - val_loss: 0.5128 - val_accuracy: 0.7432\n",
            "Epoch 25/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4868 - accuracy: 0.7562 - val_loss: 0.5122 - val_accuracy: 0.7450\n",
            "Epoch 26/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4859 - accuracy: 0.7561 - val_loss: 0.5119 - val_accuracy: 0.7430\n",
            "Epoch 27/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4857 - accuracy: 0.7569 - val_loss: 0.5179 - val_accuracy: 0.7433\n",
            "Epoch 28/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4855 - accuracy: 0.7565 - val_loss: 0.5133 - val_accuracy: 0.7430\n",
            "Epoch 29/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4852 - accuracy: 0.7568 - val_loss: 0.5217 - val_accuracy: 0.7452\n",
            "Epoch 30/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4844 - accuracy: 0.7573 - val_loss: 0.5172 - val_accuracy: 0.7451\n",
            "Epoch 31/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4840 - accuracy: 0.7550 - val_loss: 0.5160 - val_accuracy: 0.7445\n",
            "Epoch 32/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4839 - accuracy: 0.7584 - val_loss: 0.5256 - val_accuracy: 0.7436\n",
            "Epoch 33/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4829 - accuracy: 0.7598 - val_loss: 0.5254 - val_accuracy: 0.7431\n",
            "Epoch 34/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4827 - accuracy: 0.7578 - val_loss: 0.5173 - val_accuracy: 0.7467\n",
            "Epoch 35/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4833 - accuracy: 0.7578 - val_loss: 0.5252 - val_accuracy: 0.7447\n",
            "Epoch 36/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4820 - accuracy: 0.7590 - val_loss: 0.5316 - val_accuracy: 0.7432\n",
            "Epoch 37/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4810 - accuracy: 0.7601 - val_loss: 0.5365 - val_accuracy: 0.7451\n",
            "Epoch 38/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4814 - accuracy: 0.7588 - val_loss: 0.5260 - val_accuracy: 0.7450\n",
            "Epoch 39/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4795 - accuracy: 0.7600 - val_loss: 0.5524 - val_accuracy: 0.7441\n",
            "Epoch 40/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4805 - accuracy: 0.7598 - val_loss: 0.5265 - val_accuracy: 0.7453\n",
            "Epoch 41/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4794 - accuracy: 0.7612 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
            "Epoch 42/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4793 - accuracy: 0.7601 - val_loss: 0.5408 - val_accuracy: 0.7424\n",
            "Epoch 43/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4792 - accuracy: 0.7615 - val_loss: 0.5485 - val_accuracy: 0.7460\n",
            "Epoch 44/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4789 - accuracy: 0.7619 - val_loss: 0.5577 - val_accuracy: 0.7444\n",
            "Epoch 45/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4784 - accuracy: 0.7616 - val_loss: 0.5524 - val_accuracy: 0.7464\n",
            "Epoch 46/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4786 - accuracy: 0.7617 - val_loss: 0.5422 - val_accuracy: 0.7462\n",
            "Epoch 47/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4776 - accuracy: 0.7627 - val_loss: 0.5415 - val_accuracy: 0.7467\n",
            "Epoch 48/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4769 - accuracy: 0.7631 - val_loss: 0.5426 - val_accuracy: 0.7429\n",
            "Epoch 49/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4780 - accuracy: 0.7616 - val_loss: 0.5557 - val_accuracy: 0.7439\n",
            "Epoch 50/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4769 - accuracy: 0.7620 - val_loss: 0.5352 - val_accuracy: 0.7447\n",
            "Epoch 51/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4768 - accuracy: 0.7628 - val_loss: 0.5413 - val_accuracy: 0.7427\n",
            "Epoch 52/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4762 - accuracy: 0.7636 - val_loss: 0.5579 - val_accuracy: 0.7436\n",
            "Epoch 53/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4770 - accuracy: 0.7648 - val_loss: 0.5528 - val_accuracy: 0.7432\n",
            "Epoch 54/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4852 - accuracy: 0.7633 - val_loss: 0.5486 - val_accuracy: 0.7446\n",
            "Epoch 55/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4748 - accuracy: 0.7634 - val_loss: 0.5525 - val_accuracy: 0.7445\n",
            "Epoch 56/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4739 - accuracy: 0.7628 - val_loss: 0.5594 - val_accuracy: 0.7447\n",
            "Epoch 57/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4741 - accuracy: 0.7646 - val_loss: 0.5744 - val_accuracy: 0.7441\n",
            "Epoch 58/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4735 - accuracy: 0.7635 - val_loss: 0.5610 - val_accuracy: 0.7438\n",
            "Epoch 59/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4732 - accuracy: 0.7646 - val_loss: 0.5696 - val_accuracy: 0.7424\n",
            "Epoch 60/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4736 - accuracy: 0.7631 - val_loss: 0.5696 - val_accuracy: 0.7452\n",
            "Epoch 61/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4734 - accuracy: 0.7643 - val_loss: 0.5566 - val_accuracy: 0.7452\n",
            "Epoch 62/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4729 - accuracy: 0.7640 - val_loss: 0.5876 - val_accuracy: 0.7448\n",
            "Epoch 63/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4728 - accuracy: 0.7628 - val_loss: 0.5866 - val_accuracy: 0.7431\n",
            "Epoch 64/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4723 - accuracy: 0.7653 - val_loss: 0.5685 - val_accuracy: 0.7412\n",
            "Epoch 65/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4725 - accuracy: 0.7640 - val_loss: 0.5773 - val_accuracy: 0.7405\n",
            "Epoch 66/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4728 - accuracy: 0.7647 - val_loss: 0.5855 - val_accuracy: 0.7454\n",
            "Epoch 67/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4723 - accuracy: 0.7629 - val_loss: 0.5835 - val_accuracy: 0.7447\n",
            "Epoch 68/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4716 - accuracy: 0.7637 - val_loss: 0.5756 - val_accuracy: 0.7438\n",
            "Epoch 69/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4709 - accuracy: 0.7646 - val_loss: 0.5911 - val_accuracy: 0.7437\n",
            "Epoch 70/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4709 - accuracy: 0.7654 - val_loss: 0.6189 - val_accuracy: 0.7455\n",
            "Epoch 71/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4718 - accuracy: 0.7667 - val_loss: 0.5820 - val_accuracy: 0.7438\n",
            "Epoch 72/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4750 - accuracy: 0.7653 - val_loss: 0.5923 - val_accuracy: 0.7443\n",
            "Epoch 73/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4698 - accuracy: 0.7650 - val_loss: 0.6123 - val_accuracy: 0.7436\n",
            "Epoch 74/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4720 - accuracy: 0.7657 - val_loss: 0.5929 - val_accuracy: 0.7431\n",
            "Epoch 75/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4703 - accuracy: 0.7662 - val_loss: 0.5938 - val_accuracy: 0.7450\n",
            "Epoch 76/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4710 - accuracy: 0.7643 - val_loss: 0.5882 - val_accuracy: 0.7430\n",
            "Epoch 77/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4698 - accuracy: 0.7664 - val_loss: 0.5879 - val_accuracy: 0.7441\n",
            "Epoch 78/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4687 - accuracy: 0.7664 - val_loss: 0.6056 - val_accuracy: 0.7452\n",
            "Epoch 79/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4694 - accuracy: 0.7661 - val_loss: 0.6059 - val_accuracy: 0.7426\n",
            "Epoch 80/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4696 - accuracy: 0.7659 - val_loss: 0.6149 - val_accuracy: 0.7450\n",
            "Epoch 81/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4699 - accuracy: 0.7656 - val_loss: 0.6052 - val_accuracy: 0.7444\n",
            "Epoch 82/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4707 - accuracy: 0.7677 - val_loss: 0.5750 - val_accuracy: 0.7423\n",
            "Epoch 83/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4691 - accuracy: 0.7666 - val_loss: 0.6235 - val_accuracy: 0.7448\n",
            "Epoch 84/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4691 - accuracy: 0.7663 - val_loss: 0.6076 - val_accuracy: 0.7432\n",
            "Epoch 85/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4688 - accuracy: 0.7664 - val_loss: 0.6395 - val_accuracy: 0.7436\n",
            "Epoch 86/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4679 - accuracy: 0.7669 - val_loss: 0.6319 - val_accuracy: 0.7433\n",
            "Epoch 87/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4684 - accuracy: 0.7664 - val_loss: 0.6329 - val_accuracy: 0.7431\n",
            "Epoch 88/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4681 - accuracy: 0.7662 - val_loss: 0.6321 - val_accuracy: 0.7457\n",
            "Epoch 89/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4687 - accuracy: 0.7656 - val_loss: 0.6224 - val_accuracy: 0.7423\n",
            "Epoch 90/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4689 - accuracy: 0.7672 - val_loss: 0.6243 - val_accuracy: 0.7398\n",
            "Epoch 91/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4733 - accuracy: 0.7672 - val_loss: 0.6046 - val_accuracy: 0.7444\n",
            "Epoch 92/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4676 - accuracy: 0.7676 - val_loss: 0.6178 - val_accuracy: 0.7445\n",
            "Epoch 93/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4667 - accuracy: 0.7675 - val_loss: 0.6356 - val_accuracy: 0.7464\n",
            "Epoch 94/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4669 - accuracy: 0.7677 - val_loss: 0.6198 - val_accuracy: 0.7448\n",
            "Epoch 95/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4657 - accuracy: 0.7683 - val_loss: 0.6193 - val_accuracy: 0.7426\n",
            "Epoch 96/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4670 - accuracy: 0.7675 - val_loss: 0.6305 - val_accuracy: 0.7434\n",
            "Epoch 97/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4675 - accuracy: 0.7674 - val_loss: 0.6169 - val_accuracy: 0.7426\n",
            "Epoch 98/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4668 - accuracy: 0.7676 - val_loss: 0.6058 - val_accuracy: 0.7438\n",
            "Epoch 99/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4673 - accuracy: 0.7674 - val_loss: 0.5940 - val_accuracy: 0.7427\n",
            "Epoch 100/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.7668 - val_loss: 0.6116 - val_accuracy: 0.7443\n",
            "Epoch 101/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4658 - accuracy: 0.7675 - val_loss: 0.6230 - val_accuracy: 0.7429\n",
            "Epoch 102/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4661 - accuracy: 0.7688 - val_loss: 0.6366 - val_accuracy: 0.7443\n",
            "Epoch 103/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4690 - accuracy: 0.7676 - val_loss: 0.6781 - val_accuracy: 0.7416\n",
            "Epoch 104/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4679 - accuracy: 0.7664 - val_loss: 0.6586 - val_accuracy: 0.7436\n",
            "Epoch 105/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4659 - accuracy: 0.7672 - val_loss: 0.6761 - val_accuracy: 0.7462\n",
            "Epoch 106/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4653 - accuracy: 0.7677 - val_loss: 0.6865 - val_accuracy: 0.7448\n",
            "Epoch 107/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4662 - accuracy: 0.7687 - val_loss: 0.6712 - val_accuracy: 0.7433\n",
            "Epoch 108/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4668 - accuracy: 0.7700 - val_loss: 0.6859 - val_accuracy: 0.7424\n",
            "Epoch 109/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4671 - accuracy: 0.7688 - val_loss: 0.6653 - val_accuracy: 0.7439\n",
            "Epoch 110/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4664 - accuracy: 0.7690 - val_loss: 0.6470 - val_accuracy: 0.7433\n",
            "Epoch 111/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4655 - accuracy: 0.7697 - val_loss: 0.6794 - val_accuracy: 0.7418\n",
            "Epoch 112/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4661 - accuracy: 0.7675 - val_loss: 0.6921 - val_accuracy: 0.7444\n",
            "Epoch 113/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4662 - accuracy: 0.7675 - val_loss: 0.6317 - val_accuracy: 0.7429\n",
            "Epoch 114/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4646 - accuracy: 0.7674 - val_loss: 0.6782 - val_accuracy: 0.7425\n",
            "Epoch 115/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4666 - accuracy: 0.7677 - val_loss: 0.6605 - val_accuracy: 0.7415\n",
            "Epoch 116/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4662 - accuracy: 0.7672 - val_loss: 0.7194 - val_accuracy: 0.7438\n",
            "Epoch 117/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4654 - accuracy: 0.7677 - val_loss: 0.6891 - val_accuracy: 0.7424\n",
            "Epoch 118/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4657 - accuracy: 0.7691 - val_loss: 0.7476 - val_accuracy: 0.7411\n",
            "Epoch 119/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4648 - accuracy: 0.7685 - val_loss: 0.7242 - val_accuracy: 0.7431\n",
            "Epoch 120/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4645 - accuracy: 0.7687 - val_loss: 0.7573 - val_accuracy: 0.7433\n",
            "Epoch 121/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4650 - accuracy: 0.7667 - val_loss: 0.7128 - val_accuracy: 0.7411\n",
            "Epoch 122/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4651 - accuracy: 0.7676 - val_loss: 0.7260 - val_accuracy: 0.7431\n",
            "Epoch 123/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4653 - accuracy: 0.7692 - val_loss: 0.6980 - val_accuracy: 0.7440\n",
            "Epoch 124/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.5128 - accuracy: 0.7671 - val_loss: 0.8405 - val_accuracy: 0.7411\n",
            "Epoch 125/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4694 - accuracy: 0.7655 - val_loss: 0.7507 - val_accuracy: 0.7413\n",
            "Epoch 126/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4645 - accuracy: 0.7681 - val_loss: 0.7873 - val_accuracy: 0.7436\n",
            "Epoch 127/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4633 - accuracy: 0.7689 - val_loss: 0.7978 - val_accuracy: 0.7446\n",
            "Epoch 128/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4623 - accuracy: 0.7695 - val_loss: 0.7981 - val_accuracy: 0.7424\n",
            "Epoch 129/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4629 - accuracy: 0.7697 - val_loss: 0.7960 - val_accuracy: 0.7425\n",
            "Epoch 130/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4628 - accuracy: 0.7696 - val_loss: 0.8192 - val_accuracy: 0.7425\n",
            "Epoch 131/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4634 - accuracy: 0.7696 - val_loss: 0.8038 - val_accuracy: 0.7429\n",
            "Epoch 132/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4637 - accuracy: 0.7683 - val_loss: 0.7946 - val_accuracy: 0.7384\n",
            "Epoch 133/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4632 - accuracy: 0.7710 - val_loss: 0.7986 - val_accuracy: 0.7417\n",
            "Epoch 134/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4630 - accuracy: 0.7694 - val_loss: 0.8400 - val_accuracy: 0.7429\n",
            "Epoch 135/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4636 - accuracy: 0.7691 - val_loss: 0.7663 - val_accuracy: 0.7445\n",
            "Epoch 136/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4625 - accuracy: 0.7690 - val_loss: 0.8220 - val_accuracy: 0.7427\n",
            "Epoch 137/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4625 - accuracy: 0.7695 - val_loss: 0.8323 - val_accuracy: 0.7426\n",
            "Epoch 138/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4628 - accuracy: 0.7692 - val_loss: 0.7614 - val_accuracy: 0.7418\n",
            "Epoch 139/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4631 - accuracy: 0.7697 - val_loss: 0.8284 - val_accuracy: 0.7413\n",
            "Epoch 140/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4642 - accuracy: 0.7689 - val_loss: 0.7927 - val_accuracy: 0.7432\n",
            "Epoch 141/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4635 - accuracy: 0.7699 - val_loss: 0.7644 - val_accuracy: 0.7388\n",
            "Epoch 142/150\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4635 - accuracy: 0.7685 - val_loss: 0.8171 - val_accuracy: 0.7420\n",
            "Epoch 143/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4725 - accuracy: 0.7697 - val_loss: 0.7485 - val_accuracy: 0.7436\n",
            "Epoch 144/150\n",
            "804/804 [==============================] - 3s 3ms/step - loss: 0.4612 - accuracy: 0.7712 - val_loss: 0.7700 - val_accuracy: 0.7430\n",
            "Epoch 145/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4619 - accuracy: 0.7709 - val_loss: 0.7527 - val_accuracy: 0.7434\n",
            "Epoch 146/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4616 - accuracy: 0.7714 - val_loss: 0.7452 - val_accuracy: 0.7424\n",
            "Epoch 147/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4619 - accuracy: 0.7702 - val_loss: 0.7751 - val_accuracy: 0.7425\n",
            "Epoch 148/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4617 - accuracy: 0.7709 - val_loss: 0.7687 - val_accuracy: 0.7432\n",
            "Epoch 149/150\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.7401 - val_accuracy: 0.7433\n",
            "Epoch 150/150\n",
            "804/804 [==============================] - 3s 4ms/step - loss: 0.4616 - accuracy: 0.7707 - val_loss: 0.7738 - val_accuracy: 0.7438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = nn3.evaluate(X_test_scaled,y_test,verbose=1)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "id": "EJHw1og1HAAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6240f622-4804-4916-88ab-3c92d15b6d6b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "268/268 [==============================] - 0s 1ms/step - loss: 0.7738 - accuracy: 0.7438\n",
            "Loss: 0.7738019824028015, Accuracy: 0.7437900900840759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn3.save('AlphabetSoupCharity_Optimisation3.h5')"
      ],
      "metadata": {
        "id": "Pycdd0DWyUOB"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}